{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SAmple: https://github.com/Piasy/Udacity-DLND/blob/master/language-translation/dlnd_language_translation.ipynb\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "import numpy as np\n",
    "tf.reset_default_graph() #Clears the default graph stack and resets the global default graph.\n",
    "sess = tf.InteractiveSession() #initializes a tensorflow session\n",
    "data_file = open('cmudict.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc: 28\n",
      "Dec: 28\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "l1=-1\n",
    "l2=-1\n",
    "for line in data_file:\n",
    "    tok = line.split()  \n",
    "    word = tok[0]\n",
    "    if '(' in word:\n",
    "        word=word[:word.index('(')]\n",
    "    if len(word) > l1:\n",
    "        l1 = len(word)\n",
    "    phones = tok[1:]\n",
    "    if len(phones) > l2:\n",
    "        l2=len(phones)\n",
    "    data.append(list([word,phones]))\n",
    "print(\"Enc:\",l1)\n",
    "print(\"Dec:\",l2)\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'bout\", ['B', 'AW1', 'T']]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src__txt_to_int: {'j': 26, 'd': 18, 'n': 15, 'i': 13, 'z': 24, 'm': 11, 'b': 2, 't': 5, \"'\": 1, 'x': 25, '.': 21, 'f': 12, 'y': 17, 'e': 9, '-': 28, 'l': 19, 'g': 14, 'p': 29, 'c': 6, 'o': 3, '<PAD>': 0, '1': 30, 's': 8, '<UNK>': 31, 'v': 23, 'k': 16, 'u': 4, 'r': 10, 'a': 7, 'w': 20, 'q': 27, 'h': 22}\n",
      "src__int_to_txt: {0: '<PAD>', 1: \"'\", 2: 'b', 3: 'o', 4: 'u', 5: 't', 6: 'c', 7: 'a', 8: 's', 9: 'e', 10: 'r', 11: 'm', 12: 'f', 13: 'i', 14: 'g', 15: 'n', 16: 'k', 17: 'y', 18: 'd', 19: 'l', 20: 'w', 21: '.', 22: 'h', 23: 'v', 24: 'z', 25: 'x', 26: 'j', 27: 'q', 28: '-', 29: 'p', 30: '1', 31: '<UNK>'}\n"
     ]
    }
   ],
   "source": [
    "f1 = open('src.txt',\"w\")\n",
    "f2 = open('tar.txt',\"w\")\n",
    "src__txt_to_int={}\n",
    "src__int_to_txt={}\n",
    "cnt=1\n",
    "for pair in data:\n",
    "    for char in pair[0]:\n",
    "        f1.write(char+\" \")\n",
    "        if char not in src__txt_to_int:\n",
    "            src__txt_to_int[char]=cnt\n",
    "            src__int_to_txt[cnt]=char\n",
    "            cnt+=1\n",
    "    f1.write(\"\\n\")\n",
    "    for phone in pair[1]:\n",
    "        f2.write(phone+\" \")\n",
    "    f2.write(\"\\n\")\n",
    "src__txt_to_int['<PAD>']=0\n",
    "src__int_to_txt[0]='<PAD>'\n",
    "src__txt_to_int['<UNK>']=cnt\n",
    "src__int_to_txt[cnt]='<UNK>'\n",
    "print(\"src__txt_to_int:\",src__txt_to_int)\n",
    "print(\"src__int_to_txt:\",src__int_to_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt->int: {'ER1': 35, 'UW': 76, 'AE1': 7, 'AO2': 16, 'OW': 58, 'B': 25, 'ZH': 84, 'EH0': 30, 'SH': 69, 'AA1': 3, 'EH1': 31, '<PAD>': 0, 'P': 66, 'AH': 9, 'OW1': 60, 'N': 56, 'OW2': 61, 'F': 41, 'UH': 72, 'D': 27, 'EH2': 32, 'AE2': 8, 'EY2': 40, 'IY1': 50, 'EH': 29, 'DH': 28, 'EY1': 39, 'UH0': 73, 'W': 81, 'AA2': 4, 'K': 53, 'IY2': 51, 'OY2': 65, 'HH': 43, 'IH': 44, 'AO': 13, 'IH1': 46, 'AY': 21, 'S': 68, 'G': 42, 'R': 67, 'AH1': 11, 'AW0': 18, 'ER': 33, 'AH2': 12, 'AO1': 15, '<UNK>': 87, 'ER0': 34, 'AY1': 23, 'AW2': 20, 'AO0': 14, 'EY': 37, '<EOS>': 85, 'AW1': 19, 'OY': 62, 'AY0': 22, 'TH': 71, 'OY1': 64, 'UH2': 75, 'NG': 57, 'IH2': 47, 'AA0': 2, 'Z': 83, 'UH1': 74, 'L': 54, 'OW0': 59, 'M': 55, 'AA': 1, 'CH': 26, 'AW': 17, 'IY0': 49, 'EY0': 38, 'AE': 5, 'JH': 52, 'AE0': 6, 'UW0': 77, 'UW2': 79, 'OY0': 63, 'AH0': 10, 'AY2': 24, 'IH0': 45, 'ER2': 36, '<GO>': 86, 'Y': 82, 'V': 80, 'UW1': 78, 'IY': 48, 'T': 70}\n",
      "int->txt: {0: '<PAD>', 1: 'AA', 2: 'AA0', 3: 'AA1', 4: 'AA2', 5: 'AE', 6: 'AE0', 7: 'AE1', 8: 'AE2', 9: 'AH', 10: 'AH0', 11: 'AH1', 12: 'AH2', 13: 'AO', 14: 'AO0', 15: 'AO1', 16: 'AO2', 17: 'AW', 18: 'AW0', 19: 'AW1', 20: 'AW2', 21: 'AY', 22: 'AY0', 23: 'AY1', 24: 'AY2', 25: 'B', 26: 'CH', 27: 'D', 28: 'DH', 29: 'EH', 30: 'EH0', 31: 'EH1', 32: 'EH2', 33: 'ER', 34: 'ER0', 35: 'ER1', 36: 'ER2', 37: 'EY', 38: 'EY0', 39: 'EY1', 40: 'EY2', 41: 'F', 42: 'G', 43: 'HH', 44: 'IH', 45: 'IH0', 46: 'IH1', 47: 'IH2', 48: 'IY', 49: 'IY0', 50: 'IY1', 51: 'IY2', 52: 'JH', 53: 'K', 54: 'L', 55: 'M', 56: 'N', 57: 'NG', 58: 'OW', 59: 'OW0', 60: 'OW1', 61: 'OW2', 62: 'OY', 63: 'OY0', 64: 'OY1', 65: 'OY2', 66: 'P', 67: 'R', 68: 'S', 69: 'SH', 70: 'T', 71: 'TH', 72: 'UH', 73: 'UH0', 74: 'UH1', 75: 'UH2', 76: 'UW', 77: 'UW0', 78: 'UW1', 79: 'UW2', 80: 'V', 81: 'W', 82: 'Y', 83: 'Z', 84: 'ZH', 85: '<EOS>', 86: '<GO>', 87: '<UNK>'}\n"
     ]
    }
   ],
   "source": [
    "phonef = open('cmudict.symbols','r')\n",
    "tar__txt_to_int={}\n",
    "tar__int_to_txt={}\n",
    "cnt=1\n",
    "for phone in phonef:\n",
    "    phone=phone.split()\n",
    "    tar__txt_to_int[phone[0]]=cnt\n",
    "    tar__int_to_txt[cnt]=phone[0]\n",
    "    cnt+=1\n",
    "tar__txt_to_int['<EOS>']=cnt\n",
    "tar__int_to_txt[cnt]='<EOS>'\n",
    "cnt+=1\n",
    "tar__txt_to_int['<GO>']=cnt\n",
    "tar__int_to_txt[cnt]='<GO>'\n",
    "cnt+=1\n",
    "tar__txt_to_int['<UNK>']=cnt\n",
    "tar__int_to_txt[cnt]='<UNK>'\n",
    "tar__txt_to_int['<PAD>']=0\n",
    "tar__int_to_txt[0]='<PAD>'\n",
    "phonef.close()\n",
    "print(\"txt->int:\",tar__txt_to_int)\n",
    "print(\"int->txt:\",tar__int_to_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write new files in a way that tf can understand...\n",
    "f1ints = open('int_src.txt','w')\n",
    "f1 = open('src.txt',\"r\")\n",
    "src_f=[]\n",
    "tar_f=[]\n",
    "for line in f1:\n",
    "    temp=[]\n",
    "    toks = line.split()\n",
    "    for tok in toks:\n",
    "        f1ints.write(str(src__txt_to_int[tok])+\" \")\n",
    "        temp.append(src__txt_to_int[tok])\n",
    "    src_f.append(temp)\n",
    "    f1ints.write(\"\\n\")\n",
    "f2ints = open('int_tar.txt','w')\n",
    "\n",
    "f2 = open('tar.txt',\"r\")\n",
    "for line in f2:\n",
    "    temp=[]\n",
    "    toks = line.split()\n",
    "    for tok in toks:\n",
    "        if tok == '#':\n",
    "            break\n",
    "        f2ints.write(str(tar__txt_to_int[tok])+\" \")\n",
    "        temp.append(tar__txt_to_int[tok])\n",
    "    temp.append(tar__txt_to_int['<EOS>'])\n",
    "    f2ints.write(str(tar__txt_to_int['<EOS>'])+'\\n')\n",
    "    tar_f.append(temp)\n",
    "f1.close()\n",
    "f2.close()\n",
    "f1ints.close()\n",
    "f2ints.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5], [1, 6, 7, 4, 8, 9], [1, 6, 3, 4, 10, 8, 9], [1, 6, 4, 8, 9], [1, 9, 11], [1, 12, 10, 13, 8, 6, 3], [1, 14, 7, 13, 15], [1, 16, 7, 17], [1, 11], [1, 15]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preprocess finished...\n",
    "\n",
    "Split cmudict.dict into source sequence (words are letters in this sequence(makes sense!?))\n",
    "and target sequences (these are the phones) in two files:\n",
    "src sequences: src.txt\n",
    "tar sequences: tar.txt\n",
    "'''\n",
    "src_path='src.txt'\n",
    "tar_path='tar.txt'\n",
    "\n",
    "'''\n",
    "\n",
    "!!!IMPORTANT INFORMATION!!!\n",
    "datapoints with multi prounciations: src1 sequence = scr2 sequence but matching tar1 sequence != tar2 sequence\n",
    "How does this affect learning?\n",
    "\n",
    "datapoints with forgin pronunications simmilar\n",
    "How does this affect learning?\n",
    "\n",
    "should we just remove this points altogether?\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "Source:\n",
    "text_to_int dict: src__txt_to_int\n",
    "int_to_text dict: src__int_to_txt\n",
    "\n",
    "Target:\n",
    "text_to_int dict: tar__txt_to_int\n",
    "int_to_tect dict: tar__int_to_txt\n",
    "\n",
    "\n",
    "Used dictionaries to map sequences in a way that tf can understand:\n",
    "\n",
    "Source_id'd: int_src.txt\n",
    "Target_id'd: int_tar.txt\n",
    "'''\n",
    "print(src_f[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Now lets save this in a pickle file...\n",
    "'''\n",
    "#first get id's in a list:\n",
    "src_ids=[]\n",
    "tar_ids=[]\n",
    "f1 = open('int_src.txt','r')\n",
    "f2 = open('int_tar.txt','r')\n",
    "for line in f1:\n",
    "    toks = line.split()\n",
    "    src_ids.append(toks)\n",
    "for line in f2:\n",
    "    toks = line.split()\n",
    "    tar_ids.append(toks)\n",
    "f1.close()\n",
    "f2.close()\n",
    "import pickle\n",
    "with open('preprocess.p', 'wb') as out_file:\n",
    "    pickle.dump((\n",
    "            (src_f, tar_f),\n",
    "            (src__txt_to_int, tar__txt_to_int),\n",
    "            (src__int_to_txt, tar__int_to_txt)), out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#From Sample XXXX\n",
    "def model_inputs():\n",
    "    \n",
    "    \"\"\"\n",
    "    Create TF Placeholders for:\n",
    "    input, \n",
    "    targets, \n",
    "    learning rate, \n",
    "    lengths of source \n",
    "    target sequences\n",
    "    return Tuple (input, targets, learning rate, keep probability, target sequence length,\n",
    "    max target sequence length, source sequence length)\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement Function\n",
    "    inputs = tf.placeholder(tf.int32,[None,None],name=\"input\")\n",
    "    targets = tf.placeholder(tf.int32,[None,None])\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "    target_seq = tf.placeholder(tf.int32,[None],name=\"target_sequence_length\")\n",
    "    max_target = tf.reduce_max(target_seq,name=\"max_target_len\")                               \n",
    "    source_seq = tf.placeholder(tf.int32,[None],name=\"source_sequence_length\")\n",
    "    return (inputs, targets, learning_rate, keep_prob, target_seq, max_target, source_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From Sample XXXX\n",
    "def process_decoder_input(target_data, tar__txt_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for encoding\n",
    "    :param target_data: Target Placehoder\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param batch_size: Batch Size\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    cut_off = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    dec_input = tf.concat([tf.fill([batch_size, 1], tar__txt_to_int['<GO>']), cut_off], 1)\n",
    "    return dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From Sample XXXX\n",
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, \n",
    "                   source_sequence_length, source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create encoding layer\n",
    "    :param rnn_inputs: Inputs for the RNN\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :param source_sequence_length: a list of the lengths of each sequence in the batch\n",
    "    :param source_vocab_size: vocabulary size of source data\n",
    "    :param encoding_embedding_size: embedding size of source data\n",
    "    :return: tuple (RNN output, RNN state)\n",
    "    \"\"\"\n",
    "    # Encoder embedding\n",
    "    enc_embed_input = tf.contrib.layers.embed_sequence(rnn_inputs, source_vocab_size, encoding_embedding_size)\n",
    "\n",
    "    # RNN cell\n",
    "    def make_cell(rnn_size,keep_prob):\n",
    "        enc_cell = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(enc_cell, output_keep_prob = keep_prob)\n",
    "        return drop\n",
    "\n",
    "    enc_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size,keep_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    enc_output, enc_state = tf.nn.dynamic_rnn(enc_cell, enc_embed_input, sequence_length=source_sequence_length, dtype=tf.float32)\n",
    "    \n",
    "    return enc_output, enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From Sample XXXX\n",
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, \n",
    "                         target_sequence_length, max_summary_length, \n",
    "                         output_layer, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for training\n",
    "    :param encoder_state: Encoder State\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embed_input: Decoder embedded input\n",
    "    :param target_sequence_length: The lengths of each sequence in the target batch\n",
    "    :param max_summary_length: The length of the longest sequence in the batch\n",
    "    :param output_layer: Function to apply the output layer\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: BasicDecoderOutput containing training logits and sample_id\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n",
    "                                                            sequence_length=target_sequence_length,\n",
    "                                                            time_major=False)\n",
    "    \n",
    "    training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                           training_helper,\n",
    "                                                           encoder_state,\n",
    "                                                           output_layer) \n",
    "    \n",
    "    BasicDecoderOutput = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                                       impute_finished=True,\n",
    "                                                                       maximum_iterations=max_summary_length)[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    return BasicDecoderOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From Sample XXXX\n",
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id,\n",
    "                         end_of_sequence_id, max_target_sequence_length,\n",
    "                         vocab_size, output_layer, batch_size, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for inference\n",
    "    :param encoder_state: Encoder state\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embeddings: Decoder embeddings\n",
    "    :param start_of_sequence_id: GO ID\n",
    "    :param end_of_sequence_id: EOS Id\n",
    "    :param max_target_sequence_length: Maximum length of target sequences\n",
    "    :param vocab_size: Size of decoder/target vocabulary\n",
    "    :param decoding_scope: TenorFlow Variable Scope for decoding\n",
    "    :param output_layer: Function to apply the output layer\n",
    "    :param batch_size: Batch size\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: BasicDecoderOutput containing inference logits and sample_id\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        start_tokens = tf.tile(tf.constant([start_of_sequence_id], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "    \n",
    "    \n",
    "    # TODO: Implement Function\n",
    "    inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings,\n",
    "                                                                start_tokens,\n",
    "                                                                end_of_sequence_id)\n",
    "\n",
    "    # Basic decoder\n",
    "    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                    inference_helper,\n",
    "                                                    encoder_state,\n",
    "                                                    output_layer)\n",
    "\n",
    "    # Perform dynamic decoding using the decoder\n",
    "    BasicDecoderOutput = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                        impute_finished=True,\n",
    "                                                        maximum_iterations=max_target_sequence_length)[0]\n",
    "    return BasicDecoderOutput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From Sample XXXX\n",
    "def decoding_layer(dec_input, encoder_state,\n",
    "                   target_sequence_length, max_target_sequence_length,\n",
    "                   rnn_size,\n",
    "                   num_layers, target_vocab_to_int, target_vocab_size,\n",
    "                   batch_size, keep_prob, decoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    :param dec_input: Decoder input\n",
    "    :param encoder_state: Encoder state\n",
    "    :param target_sequence_length: The lengths of each sequence in the target batch\n",
    "    :param max_target_sequence_length: Maximum length of target sequences\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param target_vocab_size: Size of target vocabulary\n",
    "    :param batch_size: The size of the batch\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :param decoding_embedding_size: Decoding embedding size\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "\n",
    "    # 2. Construct the decoder cell\n",
    "    def make_cell(rnn_size):\n",
    "        dec_cell = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        return dec_cell\n",
    "\n",
    "    rnnCell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    output_layer = Dense(target_vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "    \n",
    "    Training_BasicDecoderOutput = decoding_layer_train(encoder_state, rnnCell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)\n",
    "    \n",
    "    Inference_BasicDecoderOutput = decoding_layer_infer(encoder_state, rnnCell, dec_embeddings, target_vocab_to_int['<GO>'], target_vocab_to_int['<EOS>'], max_target_sequence_length, target_vocab_size, output_layer, batch_size, keep_prob)\n",
    "    \n",
    "    return Training_BasicDecoderOutput, Inference_BasicDecoderOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From Sample XXXX\n",
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n",
    "                  source_sequence_length, target_sequence_length,\n",
    "                  max_target_sentence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size,\n",
    "                  rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence part of the neural network\n",
    "    :param input_data: Input placeholder\n",
    "    :param target_data: Target placeholder\n",
    "    :param keep_prob: Dropout keep probability placeholder\n",
    "    :param batch_size: Batch Size\n",
    "    :param source_sequence_length: Sequence Lengths of source sequences in the batch\n",
    "    :param target_sequence_length: Sequence Lengths of target sequences in the batch\n",
    "    :param source_vocab_size: Source vocabulary size\n",
    "    :param target_vocab_size: Target vocabulary size\n",
    "    :param enc_embedding_size: Decoder embedding size\n",
    "    :param dec_embedding_size: Encoder embedding size\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    _, enc_state= encoding_layer(input_data, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, enc_embedding_size)\n",
    "    \n",
    "    dec_input = process_decoder_input(target_data, target_vocab_to_int, batch_size)\n",
    "    \n",
    "    Training_BasicDecoderOutput, Inference_BasicDecoderOutput = decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)\n",
    "    \n",
    "    return Training_BasicDecoderOutput, Inference_BasicDecoderOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "epochs = 5\n",
    "# Batch Size\n",
    "batch_size = 64\n",
    "# RNN Size\n",
    "rnn_size = 128\n",
    "# Number of Layers\n",
    "num_layers = 2\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 30\n",
    "decoding_embedding_size = 30\n",
    "# Learning Rate\n",
    "learning_rate = 0.001\n",
    "# Dropout Keep Probability\n",
    "keep_probability = 0.5\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#From Sample XXXX\n",
    "save_path = 'checkpoints/dev'\n",
    "with open('preprocess.p', mode='rb') as in_file:\n",
    "    LOADED = pickle.load(in_file)\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = LOADED\n",
    "max_target_sentence_length = max([len(sentence) for sentence in source_int_text])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, lr, keep_prob, target_sequence_length, max_target_sequence_length, source_sequence_length = model_inputs()\n",
    "\n",
    "    #sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name='sequence_length')\n",
    "    input_shape = tf.shape(input_data)\n",
    "\n",
    "    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                   targets,\n",
    "                                                   keep_prob,\n",
    "                                                   batch_size,\n",
    "                                                   source_sequence_length,\n",
    "                                                   target_sequence_length,\n",
    "                                                   max_target_sequence_length,\n",
    "                                                   len(source_vocab_to_int),\n",
    "                                                   len(target_vocab_to_int),\n",
    "                                                   encoding_embedding_size,\n",
    "                                                   decoding_embedding_size,\n",
    "                                                   rnn_size,\n",
    "                                                   num_layers,\n",
    "                                                   target_vocab_to_int)\n",
    "\n",
    "\n",
    "    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From Sample XXXX\n",
    "\n",
    "#XXXXXX MODIFIED FOR OUT PROBLEM XXXXXXX#\n",
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad char seq with <PAD> so that each char sequence of a batch has the same length\"\"\"\n",
    "    max_seq = max([len(seq) for seq in sentence_batch])\n",
    "    padded_batch=[]\n",
    "    for seq in sentence_batch:\n",
    "        temp=[]\n",
    "        for char in seq:\n",
    "            temp.append(char)\n",
    "        for x in range(len(temp),max_seq):\n",
    "            temp.append(pad_int)\n",
    "        padded_batch.append(temp)\n",
    "    return padded_batch\n",
    "\n",
    "\n",
    "def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    \n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        \n",
    "        start_i = batch_i * batch_size\n",
    "\n",
    "        # Slice the right amount for the batch\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "\n",
    "        # Pad\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "\n",
    "        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch   10/2109 - Train Accuracy: 0.5000, Validation Accuracy: 0.4184, Loss: 2.3885\n",
      "Epoch   0 Batch   20/2109 - Train Accuracy: 0.3151, Validation Accuracy: 0.4549, Loss: 2.9890\n",
      "Epoch   0 Batch   30/2109 - Train Accuracy: 0.4462, Validation Accuracy: 0.4497, Loss: 2.3081\n",
      "Epoch   0 Batch   40/2109 - Train Accuracy: 0.3932, Validation Accuracy: 0.4983, Loss: 2.2687\n",
      "Epoch   0 Batch   50/2109 - Train Accuracy: 0.5760, Validation Accuracy: 0.4062, Loss: 1.8165\n",
      "Epoch   0 Batch   60/2109 - Train Accuracy: 0.3503, Validation Accuracy: 0.4774, Loss: 2.4509\n",
      "Epoch   0 Batch   70/2109 - Train Accuracy: 0.4150, Validation Accuracy: 0.4653, Loss: 2.4246\n",
      "Epoch   0 Batch   80/2109 - Train Accuracy: 0.3219, Validation Accuracy: 0.4688, Loss: 2.6044\n",
      "Epoch   0 Batch   90/2109 - Train Accuracy: 0.3906, Validation Accuracy: 0.4896, Loss: 2.3629\n",
      "Epoch   0 Batch  100/2109 - Train Accuracy: 0.4808, Validation Accuracy: 0.4983, Loss: 1.8720\n",
      "Epoch   0 Batch  110/2109 - Train Accuracy: 0.3003, Validation Accuracy: 0.4844, Loss: 2.7508\n",
      "Epoch   0 Batch  120/2109 - Train Accuracy: 0.4857, Validation Accuracy: 0.4861, Loss: 1.9232\n",
      "Epoch   0 Batch  130/2109 - Train Accuracy: 0.3846, Validation Accuracy: 0.4948, Loss: 2.0139\n",
      "Epoch   0 Batch  140/2109 - Train Accuracy: 0.4801, Validation Accuracy: 0.4896, Loss: 1.9211\n",
      "Epoch   0 Batch  150/2109 - Train Accuracy: 0.5781, Validation Accuracy: 0.4774, Loss: 1.7512\n",
      "Epoch   0 Batch  160/2109 - Train Accuracy: 0.4500, Validation Accuracy: 0.5000, Loss: 1.9528\n",
      "Epoch   0 Batch  170/2109 - Train Accuracy: 0.4972, Validation Accuracy: 0.4670, Loss: 1.8040\n",
      "Epoch   0 Batch  180/2109 - Train Accuracy: 0.5882, Validation Accuracy: 0.4392, Loss: 1.5028\n",
      "Epoch   0 Batch  190/2109 - Train Accuracy: 0.4651, Validation Accuracy: 0.4653, Loss: 1.8767\n",
      "Epoch   0 Batch  200/2109 - Train Accuracy: 0.4969, Validation Accuracy: 0.4566, Loss: 1.8033\n",
      "Epoch   0 Batch  210/2109 - Train Accuracy: 0.4797, Validation Accuracy: 0.4531, Loss: 2.2361\n",
      "Epoch   0 Batch  220/2109 - Train Accuracy: 0.5434, Validation Accuracy: 0.4705, Loss: 1.5993\n",
      "Epoch   0 Batch  230/2109 - Train Accuracy: 0.5026, Validation Accuracy: 0.4670, Loss: 1.8306\n",
      "Epoch   0 Batch  240/2109 - Train Accuracy: 0.5483, Validation Accuracy: 0.4549, Loss: 1.6043\n",
      "Epoch   0 Batch  250/2109 - Train Accuracy: 0.4943, Validation Accuracy: 0.4688, Loss: 1.9276\n",
      "Epoch   0 Batch  260/2109 - Train Accuracy: 0.5266, Validation Accuracy: 0.5122, Loss: 1.7510\n",
      "Epoch   0 Batch  270/2109 - Train Accuracy: 0.4740, Validation Accuracy: 0.5208, Loss: 2.1985\n",
      "Epoch   0 Batch  280/2109 - Train Accuracy: 0.4271, Validation Accuracy: 0.5139, Loss: 1.9691\n",
      "Epoch   0 Batch  290/2109 - Train Accuracy: 0.3672, Validation Accuracy: 0.4583, Loss: 2.1421\n",
      "Epoch   0 Batch  300/2109 - Train Accuracy: 0.4531, Validation Accuracy: 0.4826, Loss: 1.8888\n",
      "Epoch   0 Batch  310/2109 - Train Accuracy: 0.4183, Validation Accuracy: 0.4878, Loss: 2.0559\n",
      "Epoch   0 Batch  320/2109 - Train Accuracy: 0.5028, Validation Accuracy: 0.4861, Loss: 1.7493\n",
      "Epoch   0 Batch  330/2109 - Train Accuracy: 0.6380, Validation Accuracy: 0.4826, Loss: 1.3238\n",
      "Epoch   0 Batch  340/2109 - Train Accuracy: 0.4147, Validation Accuracy: 0.4774, Loss: 2.0057\n",
      "Epoch   0 Batch  350/2109 - Train Accuracy: 0.4297, Validation Accuracy: 0.5208, Loss: 2.0398\n",
      "Epoch   0 Batch  360/2109 - Train Accuracy: 0.5904, Validation Accuracy: 0.4688, Loss: 1.5943\n",
      "Epoch   0 Batch  370/2109 - Train Accuracy: 0.4577, Validation Accuracy: 0.4774, Loss: 1.8332\n",
      "Epoch   0 Batch  380/2109 - Train Accuracy: 0.4417, Validation Accuracy: 0.5104, Loss: 2.0599\n",
      "Epoch   0 Batch  390/2109 - Train Accuracy: 0.5498, Validation Accuracy: 0.4618, Loss: 1.6684\n",
      "Epoch   0 Batch  400/2109 - Train Accuracy: 0.5424, Validation Accuracy: 0.4792, Loss: 1.5940\n",
      "Epoch   0 Batch  410/2109 - Train Accuracy: 0.5156, Validation Accuracy: 0.4722, Loss: 1.6996\n",
      "Epoch   0 Batch  420/2109 - Train Accuracy: 0.5286, Validation Accuracy: 0.4427, Loss: 1.5963\n",
      "Epoch   0 Batch  430/2109 - Train Accuracy: 0.5573, Validation Accuracy: 0.4861, Loss: 1.7422\n",
      "Epoch   0 Batch  440/2109 - Train Accuracy: 0.4432, Validation Accuracy: 0.5104, Loss: 2.1210\n",
      "Epoch   0 Batch  450/2109 - Train Accuracy: 0.4347, Validation Accuracy: 0.5174, Loss: 1.7973\n",
      "Epoch   0 Batch  460/2109 - Train Accuracy: 0.6719, Validation Accuracy: 0.5243, Loss: 1.2877\n",
      "Epoch   0 Batch  470/2109 - Train Accuracy: 0.4077, Validation Accuracy: 0.4844, Loss: 1.9530\n",
      "Epoch   0 Batch  480/2109 - Train Accuracy: 0.4231, Validation Accuracy: 0.4913, Loss: 2.0012\n",
      "Epoch   0 Batch  490/2109 - Train Accuracy: 0.5406, Validation Accuracy: 0.4809, Loss: 1.6602\n",
      "Epoch   0 Batch  500/2109 - Train Accuracy: 0.4596, Validation Accuracy: 0.4601, Loss: 2.0284\n",
      "Epoch   0 Batch  510/2109 - Train Accuracy: 0.4844, Validation Accuracy: 0.4774, Loss: 1.8838\n",
      "Epoch   0 Batch  520/2109 - Train Accuracy: 0.5521, Validation Accuracy: 0.4601, Loss: 1.6090\n",
      "Epoch   0 Batch  530/2109 - Train Accuracy: 0.4938, Validation Accuracy: 0.4809, Loss: 1.7216\n",
      "Epoch   0 Batch  540/2109 - Train Accuracy: 0.5099, Validation Accuracy: 0.4722, Loss: 1.5799\n",
      "Epoch   0 Batch  550/2109 - Train Accuracy: 0.5000, Validation Accuracy: 0.4931, Loss: 1.6405\n",
      "Epoch   0 Batch  560/2109 - Train Accuracy: 0.3750, Validation Accuracy: 0.5000, Loss: 2.8697\n",
      "Epoch   0 Batch  570/2109 - Train Accuracy: 0.5996, Validation Accuracy: 0.5087, Loss: 1.3905\n",
      "Epoch   0 Batch  580/2109 - Train Accuracy: 0.5430, Validation Accuracy: 0.4757, Loss: 1.6662\n",
      "Epoch   0 Batch  590/2109 - Train Accuracy: 0.3894, Validation Accuracy: 0.4878, Loss: 2.0519\n",
      "Epoch   0 Batch  600/2109 - Train Accuracy: 0.4509, Validation Accuracy: 0.5017, Loss: 1.9267\n",
      "Epoch   0 Batch  610/2109 - Train Accuracy: 0.4857, Validation Accuracy: 0.4983, Loss: 1.7461\n",
      "Epoch   0 Batch  620/2109 - Train Accuracy: 0.4661, Validation Accuracy: 0.4965, Loss: 1.8983\n",
      "Epoch   0 Batch  630/2109 - Train Accuracy: 0.4469, Validation Accuracy: 0.4045, Loss: 1.9917\n",
      "Epoch   0 Batch  640/2109 - Train Accuracy: 0.4219, Validation Accuracy: 0.4688, Loss: 2.0254\n",
      "Epoch   0 Batch  650/2109 - Train Accuracy: 0.4188, Validation Accuracy: 0.5000, Loss: 1.8152\n",
      "Epoch   0 Batch  660/2109 - Train Accuracy: 0.5687, Validation Accuracy: 0.4844, Loss: 1.5861\n",
      "Epoch   0 Batch  670/2109 - Train Accuracy: 0.5013, Validation Accuracy: 0.4792, Loss: 1.6884\n",
      "Epoch   0 Batch  680/2109 - Train Accuracy: 0.5180, Validation Accuracy: 0.4740, Loss: 1.6312\n",
      "Epoch   0 Batch  690/2109 - Train Accuracy: 0.4808, Validation Accuracy: 0.4826, Loss: 1.7221\n",
      "Epoch   0 Batch  700/2109 - Train Accuracy: 0.4048, Validation Accuracy: 0.4792, Loss: 1.9257\n",
      "Epoch   0 Batch  710/2109 - Train Accuracy: 0.4574, Validation Accuracy: 0.4878, Loss: 2.0663\n",
      "Epoch   0 Batch  720/2109 - Train Accuracy: 0.3969, Validation Accuracy: 0.4983, Loss: 2.2809\n",
      "Epoch   0 Batch  730/2109 - Train Accuracy: 0.2676, Validation Accuracy: 0.4601, Loss: 2.1692\n",
      "Epoch   0 Batch  740/2109 - Train Accuracy: 0.3776, Validation Accuracy: 0.4167, Loss: 2.1595\n",
      "Epoch   0 Batch  750/2109 - Train Accuracy: 0.5221, Validation Accuracy: 0.4983, Loss: 1.6060\n",
      "Epoch   0 Batch  760/2109 - Train Accuracy: 0.5099, Validation Accuracy: 0.4392, Loss: 1.6547\n",
      "Epoch   0 Batch  770/2109 - Train Accuracy: 0.4828, Validation Accuracy: 0.4462, Loss: 1.5479\n",
      "Epoch   0 Batch  780/2109 - Train Accuracy: 0.6262, Validation Accuracy: 0.4497, Loss: 1.3552\n",
      "Epoch   0 Batch  790/2109 - Train Accuracy: 0.5188, Validation Accuracy: 0.4288, Loss: 1.5590\n",
      "Epoch   0 Batch  800/2109 - Train Accuracy: 0.4972, Validation Accuracy: 0.4618, Loss: 1.6784\n",
      "Epoch   0 Batch  810/2109 - Train Accuracy: 0.4344, Validation Accuracy: 0.4688, Loss: 2.1753\n",
      "Epoch   0 Batch  820/2109 - Train Accuracy: 0.4062, Validation Accuracy: 0.4705, Loss: 1.5501\n",
      "Epoch   0 Batch  830/2109 - Train Accuracy: 0.5938, Validation Accuracy: 0.4184, Loss: 1.4029\n",
      "Epoch   0 Batch  840/2109 - Train Accuracy: 0.4957, Validation Accuracy: 0.4427, Loss: 1.6283\n",
      "Epoch   0 Batch  850/2109 - Train Accuracy: 0.4656, Validation Accuracy: 0.4323, Loss: 1.5516\n",
      "Epoch   0 Batch  860/2109 - Train Accuracy: 0.5893, Validation Accuracy: 0.4358, Loss: 1.3524\n",
      "Epoch   0 Batch  870/2109 - Train Accuracy: 0.5203, Validation Accuracy: 0.4323, Loss: 1.4513\n",
      "Epoch   0 Batch  880/2109 - Train Accuracy: 0.4560, Validation Accuracy: 0.4184, Loss: 1.8680\n",
      "Epoch   0 Batch  890/2109 - Train Accuracy: 0.6031, Validation Accuracy: 0.4253, Loss: 1.4308\n",
      "Epoch   0 Batch  900/2109 - Train Accuracy: 0.4740, Validation Accuracy: 0.4149, Loss: 1.5477\n",
      "Epoch   0 Batch  910/2109 - Train Accuracy: 0.4787, Validation Accuracy: 0.4410, Loss: 2.0717\n",
      "Epoch   0 Batch  920/2109 - Train Accuracy: 0.3449, Validation Accuracy: 0.4340, Loss: 2.0938\n",
      "Epoch   0 Batch  930/2109 - Train Accuracy: 0.4615, Validation Accuracy: 0.4844, Loss: 1.8453\n",
      "Epoch   0 Batch  940/2109 - Train Accuracy: 0.4727, Validation Accuracy: 0.4670, Loss: 1.6019\n",
      "Epoch   0 Batch  950/2109 - Train Accuracy: 0.4969, Validation Accuracy: 0.4583, Loss: 1.6524\n",
      "Epoch   0 Batch  960/2109 - Train Accuracy: 0.5770, Validation Accuracy: 0.4983, Loss: 1.5139\n",
      "Epoch   0 Batch  970/2109 - Train Accuracy: 0.4961, Validation Accuracy: 0.5069, Loss: 1.4463\n",
      "Epoch   0 Batch  980/2109 - Train Accuracy: 0.6127, Validation Accuracy: 0.4427, Loss: 1.2966\n",
      "Epoch   0 Batch  990/2109 - Train Accuracy: 0.4460, Validation Accuracy: 0.4427, Loss: 1.9833\n",
      "Epoch   0 Batch 1000/2109 - Train Accuracy: 0.5526, Validation Accuracy: 0.4809, Loss: 1.4188\n",
      "Epoch   0 Batch 1010/2109 - Train Accuracy: 0.5312, Validation Accuracy: 0.4705, Loss: 1.5676\n",
      "Epoch   0 Batch 1020/2109 - Train Accuracy: 0.3872, Validation Accuracy: 0.4410, Loss: 1.8062\n",
      "Epoch   0 Batch 1030/2109 - Train Accuracy: 0.5511, Validation Accuracy: 0.4514, Loss: 1.4111\n",
      "Epoch   0 Batch 1040/2109 - Train Accuracy: 0.5057, Validation Accuracy: 0.4253, Loss: 1.4936\n",
      "Epoch   0 Batch 1050/2109 - Train Accuracy: 0.5199, Validation Accuracy: 0.4375, Loss: 1.4840\n",
      "Epoch   0 Batch 1060/2109 - Train Accuracy: 0.4105, Validation Accuracy: 0.4826, Loss: 1.6980\n",
      "Epoch   0 Batch 1070/2109 - Train Accuracy: 0.4813, Validation Accuracy: 0.4531, Loss: 1.5584\n",
      "Epoch   0 Batch 1080/2109 - Train Accuracy: 0.4740, Validation Accuracy: 0.4635, Loss: 1.7861\n",
      "Epoch   0 Batch 1090/2109 - Train Accuracy: 0.4844, Validation Accuracy: 0.4705, Loss: 1.6514\n",
      "Epoch   0 Batch 1100/2109 - Train Accuracy: 0.5104, Validation Accuracy: 0.4497, Loss: 1.4436\n",
      "Epoch   0 Batch 1110/2109 - Train Accuracy: 0.5221, Validation Accuracy: 0.4462, Loss: 1.3591\n",
      "Epoch   0 Batch 1120/2109 - Train Accuracy: 0.5637, Validation Accuracy: 0.4497, Loss: 1.5054\n",
      "Epoch   0 Batch 1130/2109 - Train Accuracy: 0.5469, Validation Accuracy: 0.4566, Loss: 1.4025\n",
      "Epoch   0 Batch 1140/2109 - Train Accuracy: 0.3672, Validation Accuracy: 0.4462, Loss: 2.1793\n",
      "Epoch   0 Batch 1150/2109 - Train Accuracy: 0.4688, Validation Accuracy: 0.4618, Loss: 1.6765\n",
      "Epoch   0 Batch 1160/2109 - Train Accuracy: 0.4375, Validation Accuracy: 0.4323, Loss: 1.4886\n",
      "Epoch   0 Batch 1170/2109 - Train Accuracy: 0.4562, Validation Accuracy: 0.4531, Loss: 1.5987\n",
      "Epoch   0 Batch 1180/2109 - Train Accuracy: 0.6261, Validation Accuracy: 0.4288, Loss: 1.3058\n",
      "Epoch   0 Batch 1190/2109 - Train Accuracy: 0.3778, Validation Accuracy: 0.4531, Loss: 1.7466\n",
      "Epoch   0 Batch 1200/2109 - Train Accuracy: 0.4886, Validation Accuracy: 0.3663, Loss: 1.5300\n",
      "Epoch   0 Batch 1210/2109 - Train Accuracy: 0.5651, Validation Accuracy: 0.4271, Loss: 1.3143\n",
      "Epoch   0 Batch 1220/2109 - Train Accuracy: 0.5993, Validation Accuracy: 0.4497, Loss: 1.3046\n",
      "Epoch   0 Batch 1230/2109 - Train Accuracy: 0.4896, Validation Accuracy: 0.4531, Loss: 1.5256\n",
      "Epoch   0 Batch 1240/2109 - Train Accuracy: 0.5199, Validation Accuracy: 0.4062, Loss: 1.3474\n",
      "Epoch   0 Batch 1250/2109 - Train Accuracy: 0.4641, Validation Accuracy: 0.4583, Loss: 1.7672\n",
      "Epoch   0 Batch 1260/2109 - Train Accuracy: 0.5603, Validation Accuracy: 0.4635, Loss: 1.5043\n",
      "Epoch   0 Batch 1270/2109 - Train Accuracy: 0.5256, Validation Accuracy: 0.4549, Loss: 1.3363\n",
      "Epoch   0 Batch 1280/2109 - Train Accuracy: 0.5156, Validation Accuracy: 0.4201, Loss: 1.6987\n",
      "Epoch   0 Batch 1290/2109 - Train Accuracy: 0.4156, Validation Accuracy: 0.4531, Loss: 2.1200\n",
      "Epoch   0 Batch 1300/2109 - Train Accuracy: 0.5000, Validation Accuracy: 0.4583, Loss: 1.5347\n",
      "Epoch   0 Batch 1310/2109 - Train Accuracy: 0.5339, Validation Accuracy: 0.4722, Loss: 1.6388\n",
      "Epoch   0 Batch 1320/2109 - Train Accuracy: 0.5355, Validation Accuracy: 0.4375, Loss: 1.4318\n",
      "Epoch   0 Batch 1330/2109 - Train Accuracy: 0.4023, Validation Accuracy: 0.4271, Loss: 1.9042\n",
      "Epoch   0 Batch 1340/2109 - Train Accuracy: 0.3733, Validation Accuracy: 0.4722, Loss: 2.3899\n",
      "Epoch   0 Batch 1350/2109 - Train Accuracy: 0.3844, Validation Accuracy: 0.4809, Loss: 2.0905\n",
      "Epoch   0 Batch 1360/2109 - Train Accuracy: 0.4509, Validation Accuracy: 0.4896, Loss: 1.6269\n",
      "Epoch   0 Batch 1370/2109 - Train Accuracy: 0.5413, Validation Accuracy: 0.4844, Loss: 1.4349\n",
      "Epoch   0 Batch 1380/2109 - Train Accuracy: 0.3337, Validation Accuracy: 0.4878, Loss: 1.8281\n",
      "Epoch   0 Batch 1390/2109 - Train Accuracy: 0.5273, Validation Accuracy: 0.4896, Loss: 1.4845\n",
      "Epoch   0 Batch 1400/2109 - Train Accuracy: 0.6266, Validation Accuracy: 0.5035, Loss: 1.1210\n",
      "Epoch   0 Batch 1410/2109 - Train Accuracy: 0.6016, Validation Accuracy: 0.4826, Loss: 1.3133\n",
      "Epoch   0 Batch 1420/2109 - Train Accuracy: 0.5234, Validation Accuracy: 0.4462, Loss: 1.3919\n",
      "Epoch   0 Batch 1430/2109 - Train Accuracy: 0.5014, Validation Accuracy: 0.4531, Loss: 1.4783\n",
      "Epoch   0 Batch 1440/2109 - Train Accuracy: 0.4719, Validation Accuracy: 0.4583, Loss: 1.5867\n",
      "Epoch   0 Batch 1450/2109 - Train Accuracy: 0.5221, Validation Accuracy: 0.4097, Loss: 1.3447\n",
      "Epoch   0 Batch 1460/2109 - Train Accuracy: 0.5227, Validation Accuracy: 0.4514, Loss: 1.4376\n",
      "Epoch   0 Batch 1470/2109 - Train Accuracy: 0.5195, Validation Accuracy: 0.4444, Loss: 1.3610\n",
      "Epoch   0 Batch 1480/2109 - Train Accuracy: 0.4308, Validation Accuracy: 0.4514, Loss: 1.7729\n",
      "Epoch   0 Batch 1490/2109 - Train Accuracy: 0.4872, Validation Accuracy: 0.4618, Loss: 1.4940\n",
      "Epoch   0 Batch 1500/2109 - Train Accuracy: 0.5271, Validation Accuracy: 0.4219, Loss: 1.3157\n",
      "Epoch   0 Batch 1510/2109 - Train Accuracy: 0.4922, Validation Accuracy: 0.4774, Loss: 1.6383\n",
      "Epoch   0 Batch 1520/2109 - Train Accuracy: 0.4036, Validation Accuracy: 0.4965, Loss: 2.0474\n",
      "Epoch   0 Batch 1530/2109 - Train Accuracy: 0.4656, Validation Accuracy: 0.4740, Loss: 1.4705\n",
      "Epoch   0 Batch 1540/2109 - Train Accuracy: 0.5399, Validation Accuracy: 0.4705, Loss: 1.4338\n",
      "Epoch   0 Batch 1550/2109 - Train Accuracy: 0.4219, Validation Accuracy: 0.5139, Loss: 1.6534\n",
      "Epoch   0 Batch 1560/2109 - Train Accuracy: 0.4856, Validation Accuracy: 0.4497, Loss: 1.3959\n",
      "Epoch   0 Batch 1570/2109 - Train Accuracy: 0.4916, Validation Accuracy: 0.4497, Loss: 1.4560\n",
      "Epoch   0 Batch 1580/2109 - Train Accuracy: 0.5349, Validation Accuracy: 0.4392, Loss: 1.4331\n",
      "Epoch   0 Batch 1590/2109 - Train Accuracy: 0.5792, Validation Accuracy: 0.4097, Loss: 1.2989\n",
      "Epoch   0 Batch 1600/2109 - Train Accuracy: 0.5312, Validation Accuracy: 0.4583, Loss: 1.3431\n",
      "Epoch   0 Batch 1610/2109 - Train Accuracy: 0.4828, Validation Accuracy: 0.4219, Loss: 1.4398\n",
      "Epoch   0 Batch 1620/2109 - Train Accuracy: 0.4883, Validation Accuracy: 0.4080, Loss: 1.5897\n",
      "Epoch   0 Batch 1630/2109 - Train Accuracy: 0.5608, Validation Accuracy: 0.4497, Loss: 1.3599\n",
      "Epoch   0 Batch 1640/2109 - Train Accuracy: 0.4989, Validation Accuracy: 0.4010, Loss: 1.5844\n",
      "Epoch   0 Batch 1650/2109 - Train Accuracy: 0.3659, Validation Accuracy: 0.4045, Loss: 1.6367\n",
      "Epoch   0 Batch 1660/2109 - Train Accuracy: 0.6654, Validation Accuracy: 0.4410, Loss: 1.1199\n",
      "Epoch   0 Batch 1670/2109 - Train Accuracy: 0.3715, Validation Accuracy: 0.4618, Loss: 2.0890\n",
      "Epoch   0 Batch 1680/2109 - Train Accuracy: 0.3466, Validation Accuracy: 0.4358, Loss: 1.6597\n",
      "Epoch   0 Batch 1690/2109 - Train Accuracy: 0.5733, Validation Accuracy: 0.4427, Loss: 1.3100\n",
      "Epoch   0 Batch 1700/2109 - Train Accuracy: 0.5469, Validation Accuracy: 0.4410, Loss: 1.2893\n",
      "Epoch   0 Batch 1710/2109 - Train Accuracy: 0.3766, Validation Accuracy: 0.4427, Loss: 1.7974\n",
      "Epoch   0 Batch 1720/2109 - Train Accuracy: 0.5028, Validation Accuracy: 0.4184, Loss: 1.4192\n",
      "Epoch   0 Batch 1730/2109 - Train Accuracy: 0.3953, Validation Accuracy: 0.4410, Loss: 1.6252\n",
      "Epoch   0 Batch 1740/2109 - Train Accuracy: 0.4616, Validation Accuracy: 0.4358, Loss: 1.3827\n",
      "Epoch   0 Batch 1750/2109 - Train Accuracy: 0.4688, Validation Accuracy: 0.4826, Loss: 1.5273\n",
      "Epoch   0 Batch 1760/2109 - Train Accuracy: 0.5156, Validation Accuracy: 0.4896, Loss: 1.5370\n",
      "Epoch   0 Batch 1770/2109 - Train Accuracy: 0.5841, Validation Accuracy: 0.4549, Loss: 1.2260\n",
      "Epoch   0 Batch 1780/2109 - Train Accuracy: 0.5028, Validation Accuracy: 0.4340, Loss: 1.3679\n",
      "Epoch   0 Batch 1790/2109 - Train Accuracy: 0.4560, Validation Accuracy: 0.4549, Loss: 1.6191\n",
      "Epoch   0 Batch 1800/2109 - Train Accuracy: 0.4567, Validation Accuracy: 0.4323, Loss: 1.3002\n",
      "Epoch   0 Batch 1810/2109 - Train Accuracy: 0.6875, Validation Accuracy: 0.4410, Loss: 0.9976\n",
      "Epoch   0 Batch 1820/2109 - Train Accuracy: 0.5915, Validation Accuracy: 0.4444, Loss: 1.2145\n",
      "Epoch   0 Batch 1830/2109 - Train Accuracy: 0.4509, Validation Accuracy: 0.4236, Loss: 1.9580\n",
      "Epoch   0 Batch 1840/2109 - Train Accuracy: 0.5281, Validation Accuracy: 0.4375, Loss: 1.5821\n",
      "Epoch   0 Batch 1850/2109 - Train Accuracy: 0.4313, Validation Accuracy: 0.4705, Loss: 1.4998\n",
      "Epoch   0 Batch 1860/2109 - Train Accuracy: 0.5247, Validation Accuracy: 0.4358, Loss: 1.5189\n",
      "Epoch   0 Batch 1870/2109 - Train Accuracy: 0.5144, Validation Accuracy: 0.4549, Loss: 1.3259\n",
      "Epoch   0 Batch 1880/2109 - Train Accuracy: 0.5526, Validation Accuracy: 0.4601, Loss: 1.3329\n",
      "Epoch   0 Batch 1890/2109 - Train Accuracy: 0.5141, Validation Accuracy: 0.4635, Loss: 1.5181\n",
      "Epoch   0 Batch 1900/2109 - Train Accuracy: 0.5554, Validation Accuracy: 0.4514, Loss: 1.1513\n",
      "Epoch   0 Batch 1910/2109 - Train Accuracy: 0.5828, Validation Accuracy: 0.4479, Loss: 1.3297\n",
      "Epoch   0 Batch 1920/2109 - Train Accuracy: 0.4974, Validation Accuracy: 0.4549, Loss: 1.3637\n",
      "Epoch   0 Batch 1930/2109 - Train Accuracy: 0.5327, Validation Accuracy: 0.5104, Loss: 1.2922\n",
      "Epoch   0 Batch 1940/2109 - Train Accuracy: 0.4602, Validation Accuracy: 0.4705, Loss: 1.4188\n",
      "Epoch   0 Batch 1950/2109 - Train Accuracy: 0.3894, Validation Accuracy: 0.4844, Loss: 2.0064\n",
      "Epoch   0 Batch 1960/2109 - Train Accuracy: 0.4260, Validation Accuracy: 0.5052, Loss: 1.7220\n",
      "Epoch   0 Batch 1970/2109 - Train Accuracy: 0.3344, Validation Accuracy: 0.4705, Loss: 1.9109\n",
      "Epoch   0 Batch 1980/2109 - Train Accuracy: 0.2578, Validation Accuracy: 0.4722, Loss: 1.9994\n",
      "Epoch   0 Batch 1990/2109 - Train Accuracy: 0.4141, Validation Accuracy: 0.4913, Loss: 1.3443\n",
      "Epoch   0 Batch 2000/2109 - Train Accuracy: 0.5195, Validation Accuracy: 0.4688, Loss: 1.4224\n",
      "Epoch   0 Batch 2010/2109 - Train Accuracy: 0.5344, Validation Accuracy: 0.4427, Loss: 1.3289\n",
      "Epoch   0 Batch 2020/2109 - Train Accuracy: 0.4531, Validation Accuracy: 0.4514, Loss: 1.4962\n",
      "Epoch   0 Batch 2030/2109 - Train Accuracy: 0.4566, Validation Accuracy: 0.4549, Loss: 1.6227\n",
      "Epoch   0 Batch 2040/2109 - Train Accuracy: 0.5469, Validation Accuracy: 0.3941, Loss: 1.2420\n",
      "Epoch   0 Batch 2050/2109 - Train Accuracy: 0.4047, Validation Accuracy: 0.4306, Loss: 1.5778\n",
      "Epoch   0 Batch 2060/2109 - Train Accuracy: 0.5297, Validation Accuracy: 0.4132, Loss: 1.2477\n",
      "Epoch   0 Batch 2070/2109 - Train Accuracy: 0.5286, Validation Accuracy: 0.4427, Loss: 1.4121\n",
      "Epoch   0 Batch 2080/2109 - Train Accuracy: 0.6250, Validation Accuracy: 0.4375, Loss: 1.0787\n",
      "Epoch   0 Batch 2090/2109 - Train Accuracy: 0.4132, Validation Accuracy: 0.4479, Loss: 1.6610\n",
      "Epoch   0 Batch 2100/2109 - Train Accuracy: 0.6621, Validation Accuracy: 0.4358, Loss: 0.9510\n",
      "Epoch   1 Batch   10/2109 - Train Accuracy: 0.5349, Validation Accuracy: 0.4462, Loss: 1.3764\n",
      "Epoch   1 Batch   20/2109 - Train Accuracy: 0.3529, Validation Accuracy: 0.4444, Loss: 1.8339\n",
      "Epoch   1 Batch   30/2109 - Train Accuracy: 0.5069, Validation Accuracy: 0.5000, Loss: 1.2949\n",
      "Epoch   1 Batch   40/2109 - Train Accuracy: 0.4792, Validation Accuracy: 0.5365, Loss: 1.4268\n",
      "Epoch   1 Batch   50/2109 - Train Accuracy: 0.6229, Validation Accuracy: 0.5035, Loss: 1.2059\n",
      "Epoch   1 Batch   60/2109 - Train Accuracy: 0.4232, Validation Accuracy: 0.5642, Loss: 1.4458\n",
      "Epoch   1 Batch   70/2109 - Train Accuracy: 0.5068, Validation Accuracy: 0.5243, Loss: 1.4618\n",
      "Epoch   1 Batch   80/2109 - Train Accuracy: 0.3734, Validation Accuracy: 0.5469, Loss: 1.6519\n",
      "Epoch   1 Batch   90/2109 - Train Accuracy: 0.4437, Validation Accuracy: 0.5347, Loss: 1.6126\n",
      "Epoch   1 Batch  100/2109 - Train Accuracy: 0.5276, Validation Accuracy: 0.4931, Loss: 1.3368\n",
      "Epoch   1 Batch  110/2109 - Train Accuracy: 0.3698, Validation Accuracy: 0.5330, Loss: 1.8560\n",
      "Epoch   1 Batch  120/2109 - Train Accuracy: 0.4935, Validation Accuracy: 0.5312, Loss: 1.2534\n",
      "Epoch   1 Batch  130/2109 - Train Accuracy: 0.4976, Validation Accuracy: 0.4514, Loss: 1.4011\n",
      "Epoch   1 Batch  140/2109 - Train Accuracy: 0.5724, Validation Accuracy: 0.4479, Loss: 1.3071\n",
      "Epoch   1 Batch  150/2109 - Train Accuracy: 0.5651, Validation Accuracy: 0.4549, Loss: 1.3011\n",
      "Epoch   1 Batch  160/2109 - Train Accuracy: 0.5797, Validation Accuracy: 0.4601, Loss: 1.3092\n",
      "Epoch   1 Batch  170/2109 - Train Accuracy: 0.5852, Validation Accuracy: 0.4497, Loss: 1.1945\n",
      "Epoch   1 Batch  180/2109 - Train Accuracy: 0.6797, Validation Accuracy: 0.4618, Loss: 0.8892\n",
      "Epoch   1 Batch  190/2109 - Train Accuracy: 0.4772, Validation Accuracy: 0.4740, Loss: 1.3322\n",
      "Epoch   1 Batch  200/2109 - Train Accuracy: 0.4938, Validation Accuracy: 0.4722, Loss: 1.2441\n",
      "Epoch   1 Batch  210/2109 - Train Accuracy: 0.5062, Validation Accuracy: 0.4722, Loss: 1.3798\n",
      "Epoch   1 Batch  220/2109 - Train Accuracy: 0.6024, Validation Accuracy: 0.4809, Loss: 1.0895\n",
      "Epoch   1 Batch  230/2109 - Train Accuracy: 0.5456, Validation Accuracy: 0.4913, Loss: 1.2610\n",
      "Epoch   1 Batch  240/2109 - Train Accuracy: 0.6037, Validation Accuracy: 0.5417, Loss: 1.1026\n",
      "Epoch   1 Batch  250/2109 - Train Accuracy: 0.4688, Validation Accuracy: 0.4635, Loss: 1.3787\n",
      "Epoch   1 Batch  260/2109 - Train Accuracy: 0.4562, Validation Accuracy: 0.5000, Loss: 1.1339\n",
      "Epoch   1 Batch  270/2109 - Train Accuracy: 0.4479, Validation Accuracy: 0.5226, Loss: 1.6755\n",
      "Epoch   1 Batch  280/2109 - Train Accuracy: 0.4688, Validation Accuracy: 0.5226, Loss: 1.2819\n",
      "Epoch   1 Batch  290/2109 - Train Accuracy: 0.4781, Validation Accuracy: 0.4479, Loss: 1.4016\n",
      "Epoch   1 Batch  300/2109 - Train Accuracy: 0.5056, Validation Accuracy: 0.4618, Loss: 1.3309\n",
      "Epoch   1 Batch  310/2109 - Train Accuracy: 0.5108, Validation Accuracy: 0.4306, Loss: 1.4447\n",
      "Epoch   1 Batch  320/2109 - Train Accuracy: 0.5426, Validation Accuracy: 0.4653, Loss: 1.1835\n",
      "Epoch   1 Batch  330/2109 - Train Accuracy: 0.6571, Validation Accuracy: 0.4774, Loss: 0.9659\n",
      "Epoch   1 Batch  340/2109 - Train Accuracy: 0.4315, Validation Accuracy: 0.4566, Loss: 1.3885\n",
      "Epoch   1 Batch  350/2109 - Train Accuracy: 0.4031, Validation Accuracy: 0.4826, Loss: 1.5318\n",
      "Epoch   1 Batch  360/2109 - Train Accuracy: 0.5435, Validation Accuracy: 0.4566, Loss: 1.0877\n",
      "Epoch   1 Batch  370/2109 - Train Accuracy: 0.4982, Validation Accuracy: 0.4913, Loss: 1.3102\n",
      "Epoch   1 Batch  380/2109 - Train Accuracy: 0.4917, Validation Accuracy: 0.4479, Loss: 1.4814\n",
      "Epoch   1 Batch  390/2109 - Train Accuracy: 0.5957, Validation Accuracy: 0.4115, Loss: 1.0524\n",
      "Epoch   1 Batch  400/2109 - Train Accuracy: 0.5859, Validation Accuracy: 0.4392, Loss: 1.0758\n",
      "Epoch   1 Batch  410/2109 - Train Accuracy: 0.5538, Validation Accuracy: 0.4566, Loss: 1.1338\n",
      "Epoch   1 Batch  420/2109 - Train Accuracy: 0.5404, Validation Accuracy: 0.4531, Loss: 1.1390\n",
      "Epoch   1 Batch  430/2109 - Train Accuracy: 0.5195, Validation Accuracy: 0.4514, Loss: 1.2478\n",
      "Epoch   1 Batch  440/2109 - Train Accuracy: 0.4531, Validation Accuracy: 0.5104, Loss: 1.4666\n",
      "Epoch   1 Batch  450/2109 - Train Accuracy: 0.5440, Validation Accuracy: 0.5243, Loss: 1.1571\n",
      "Epoch   1 Batch  460/2109 - Train Accuracy: 0.6685, Validation Accuracy: 0.5174, Loss: 0.7863\n",
      "Epoch   1 Batch  470/2109 - Train Accuracy: 0.5312, Validation Accuracy: 0.4479, Loss: 1.2885\n",
      "Epoch   1 Batch  480/2109 - Train Accuracy: 0.4351, Validation Accuracy: 0.4566, Loss: 1.3091\n",
      "Epoch   1 Batch  490/2109 - Train Accuracy: 0.5875, Validation Accuracy: 0.4670, Loss: 1.1308\n",
      "Epoch   1 Batch  500/2109 - Train Accuracy: 0.5456, Validation Accuracy: 0.4601, Loss: 1.3920\n",
      "Epoch   1 Batch  510/2109 - Train Accuracy: 0.5487, Validation Accuracy: 0.4688, Loss: 1.2936\n",
      "Epoch   1 Batch  520/2109 - Train Accuracy: 0.5521, Validation Accuracy: 0.4531, Loss: 1.0583\n",
      "Epoch   1 Batch  530/2109 - Train Accuracy: 0.5922, Validation Accuracy: 0.4688, Loss: 1.0844\n",
      "Epoch   1 Batch  540/2109 - Train Accuracy: 0.5625, Validation Accuracy: 0.4566, Loss: 1.0900\n",
      "Epoch   1 Batch  550/2109 - Train Accuracy: 0.5719, Validation Accuracy: 0.5312, Loss: 1.1353\n",
      "Epoch   1 Batch  560/2109 - Train Accuracy: 0.2812, Validation Accuracy: 0.4913, Loss: 2.4382\n",
      "Epoch   1 Batch  570/2109 - Train Accuracy: 0.6309, Validation Accuracy: 0.5642, Loss: 0.9395\n",
      "Epoch   1 Batch  580/2109 - Train Accuracy: 0.5443, Validation Accuracy: 0.5590, Loss: 1.0424\n",
      "Epoch   1 Batch  590/2109 - Train Accuracy: 0.4784, Validation Accuracy: 0.5799, Loss: 1.3087\n",
      "Epoch   1 Batch  600/2109 - Train Accuracy: 0.5603, Validation Accuracy: 0.5208, Loss: 1.1569\n",
      "Epoch   1 Batch  610/2109 - Train Accuracy: 0.5807, Validation Accuracy: 0.5903, Loss: 1.1270\n",
      "Epoch   1 Batch  620/2109 - Train Accuracy: 0.4831, Validation Accuracy: 0.5729, Loss: 1.2488\n",
      "Epoch   1 Batch  630/2109 - Train Accuracy: 0.4104, Validation Accuracy: 0.4913, Loss: 1.0697\n",
      "Epoch   1 Batch  640/2109 - Train Accuracy: 0.4284, Validation Accuracy: 0.5712, Loss: 1.3638\n",
      "Epoch   1 Batch  650/2109 - Train Accuracy: 0.6219, Validation Accuracy: 0.4983, Loss: 1.0602\n",
      "Epoch   1 Batch  660/2109 - Train Accuracy: 0.6656, Validation Accuracy: 0.4653, Loss: 1.0022\n",
      "Epoch   1 Batch  670/2109 - Train Accuracy: 0.6042, Validation Accuracy: 0.4705, Loss: 1.0332\n",
      "Epoch   1 Batch  680/2109 - Train Accuracy: 0.6142, Validation Accuracy: 0.4878, Loss: 1.1037\n",
      "Epoch   1 Batch  690/2109 - Train Accuracy: 0.4844, Validation Accuracy: 0.4809, Loss: 1.0209\n",
      "Epoch   1 Batch  700/2109 - Train Accuracy: 0.4730, Validation Accuracy: 0.5278, Loss: 1.2263\n",
      "Epoch   1 Batch  710/2109 - Train Accuracy: 0.4688, Validation Accuracy: 0.5191, Loss: 1.4227\n",
      "Epoch   1 Batch  720/2109 - Train Accuracy: 0.3891, Validation Accuracy: 0.5434, Loss: 1.4126\n",
      "Epoch   1 Batch  730/2109 - Train Accuracy: 0.5566, Validation Accuracy: 0.5312, Loss: 1.2454\n",
      "Epoch   1 Batch  740/2109 - Train Accuracy: 0.4375, Validation Accuracy: 0.4722, Loss: 1.4478\n",
      "Epoch   1 Batch  750/2109 - Train Accuracy: 0.6146, Validation Accuracy: 0.5156, Loss: 0.9047\n",
      "Epoch   1 Batch  760/2109 - Train Accuracy: 0.5398, Validation Accuracy: 0.5556, Loss: 1.1824\n",
      "Epoch   1 Batch  770/2109 - Train Accuracy: 0.5703, Validation Accuracy: 0.5226, Loss: 0.8595\n",
      "Epoch   1 Batch  780/2109 - Train Accuracy: 0.7115, Validation Accuracy: 0.5347, Loss: 0.8190\n",
      "Epoch   1 Batch  790/2109 - Train Accuracy: 0.7047, Validation Accuracy: 0.5295, Loss: 0.9143\n",
      "Epoch   1 Batch  800/2109 - Train Accuracy: 0.5568, Validation Accuracy: 0.5104, Loss: 0.9912\n",
      "Epoch   1 Batch  810/2109 - Train Accuracy: 0.4500, Validation Accuracy: 0.5365, Loss: 1.4208\n",
      "Epoch   1 Batch  820/2109 - Train Accuracy: 0.7443, Validation Accuracy: 0.4931, Loss: 0.7768\n",
      "Epoch   1 Batch  830/2109 - Train Accuracy: 0.7297, Validation Accuracy: 0.4688, Loss: 0.7700\n",
      "Epoch   1 Batch  840/2109 - Train Accuracy: 0.5781, Validation Accuracy: 0.4774, Loss: 1.0233\n",
      "Epoch   1 Batch  850/2109 - Train Accuracy: 0.5781, Validation Accuracy: 0.4306, Loss: 0.9980\n",
      "Epoch   1 Batch  860/2109 - Train Accuracy: 0.6127, Validation Accuracy: 0.4201, Loss: 1.0173\n",
      "Epoch   1 Batch  870/2109 - Train Accuracy: 0.5719, Validation Accuracy: 0.4184, Loss: 0.9343\n",
      "Epoch   1 Batch  880/2109 - Train Accuracy: 0.5256, Validation Accuracy: 0.4306, Loss: 1.2899\n",
      "Epoch   1 Batch  890/2109 - Train Accuracy: 0.6813, Validation Accuracy: 0.4184, Loss: 0.8969\n",
      "Epoch   1 Batch  900/2109 - Train Accuracy: 0.4757, Validation Accuracy: 0.3958, Loss: 0.9682\n",
      "Epoch   1 Batch  910/2109 - Train Accuracy: 0.4972, Validation Accuracy: 0.4149, Loss: 1.5644\n",
      "Epoch   1 Batch  920/2109 - Train Accuracy: 0.4754, Validation Accuracy: 0.4236, Loss: 1.3338\n",
      "Epoch   1 Batch  930/2109 - Train Accuracy: 0.5594, Validation Accuracy: 0.4809, Loss: 1.1809\n",
      "Epoch   1 Batch  940/2109 - Train Accuracy: 0.5518, Validation Accuracy: 0.5052, Loss: 1.1751\n",
      "Epoch   1 Batch  950/2109 - Train Accuracy: 0.4771, Validation Accuracy: 0.5035, Loss: 1.0349\n",
      "Epoch   1 Batch  960/2109 - Train Accuracy: 0.6060, Validation Accuracy: 0.5365, Loss: 1.0449\n",
      "Epoch   1 Batch  970/2109 - Train Accuracy: 0.5169, Validation Accuracy: 0.4878, Loss: 0.9736\n",
      "Epoch   1 Batch  980/2109 - Train Accuracy: 0.6786, Validation Accuracy: 0.4861, Loss: 0.8176\n",
      "Epoch   1 Batch  990/2109 - Train Accuracy: 0.5526, Validation Accuracy: 0.4097, Loss: 1.3147\n",
      "Epoch   1 Batch 1000/2109 - Train Accuracy: 0.7486, Validation Accuracy: 0.4670, Loss: 0.7356\n",
      "Epoch   1 Batch 1010/2109 - Train Accuracy: 0.6733, Validation Accuracy: 0.4722, Loss: 0.9835\n",
      "Epoch   1 Batch 1020/2109 - Train Accuracy: 0.5399, Validation Accuracy: 0.4774, Loss: 1.0154\n",
      "Epoch   1 Batch 1030/2109 - Train Accuracy: 0.6108, Validation Accuracy: 0.5347, Loss: 0.8759\n",
      "Epoch   1 Batch 1040/2109 - Train Accuracy: 0.6449, Validation Accuracy: 0.4583, Loss: 0.9091\n",
      "Epoch   1 Batch 1050/2109 - Train Accuracy: 0.6065, Validation Accuracy: 0.4792, Loss: 0.9657\n",
      "Epoch   1 Batch 1060/2109 - Train Accuracy: 0.6420, Validation Accuracy: 0.5174, Loss: 0.8642\n",
      "Epoch   1 Batch 1070/2109 - Train Accuracy: 0.7203, Validation Accuracy: 0.4774, Loss: 0.7736\n",
      "Epoch   1 Batch 1080/2109 - Train Accuracy: 0.5885, Validation Accuracy: 0.4410, Loss: 1.0362\n",
      "Epoch   1 Batch 1090/2109 - Train Accuracy: 0.5422, Validation Accuracy: 0.4566, Loss: 1.0930\n",
      "Epoch   1 Batch 1100/2109 - Train Accuracy: 0.6237, Validation Accuracy: 0.4444, Loss: 0.9306\n",
      "Epoch   1 Batch 1110/2109 - Train Accuracy: 0.6615, Validation Accuracy: 0.4497, Loss: 0.8129\n",
      "Epoch   1 Batch 1120/2109 - Train Accuracy: 0.6094, Validation Accuracy: 0.4809, Loss: 1.0338\n",
      "Epoch   1 Batch 1130/2109 - Train Accuracy: 0.6263, Validation Accuracy: 0.4479, Loss: 0.9217\n",
      "Epoch   1 Batch 1140/2109 - Train Accuracy: 0.4076, Validation Accuracy: 0.4792, Loss: 1.4151\n",
      "Epoch   1 Batch 1150/2109 - Train Accuracy: 0.5924, Validation Accuracy: 0.4670, Loss: 0.9923\n",
      "Epoch   1 Batch 1160/2109 - Train Accuracy: 0.6625, Validation Accuracy: 0.4410, Loss: 0.8566\n",
      "Epoch   1 Batch 1170/2109 - Train Accuracy: 0.5734, Validation Accuracy: 0.4757, Loss: 0.8248\n",
      "Epoch   1 Batch 1180/2109 - Train Accuracy: 0.6529, Validation Accuracy: 0.4271, Loss: 0.7646\n",
      "Epoch   1 Batch 1190/2109 - Train Accuracy: 0.4972, Validation Accuracy: 0.4410, Loss: 1.0537\n",
      "Epoch   1 Batch 1200/2109 - Train Accuracy: 0.5170, Validation Accuracy: 0.4236, Loss: 0.9185\n",
      "Epoch   1 Batch 1210/2109 - Train Accuracy: 0.6029, Validation Accuracy: 0.4601, Loss: 0.8984\n",
      "Epoch   1 Batch 1220/2109 - Train Accuracy: 0.6451, Validation Accuracy: 0.4479, Loss: 0.8873\n",
      "Epoch   1 Batch 1230/2109 - Train Accuracy: 0.5820, Validation Accuracy: 0.4583, Loss: 1.0833\n",
      "Epoch   1 Batch 1240/2109 - Train Accuracy: 0.7301, Validation Accuracy: 0.4514, Loss: 0.6848\n",
      "Epoch   1 Batch 1250/2109 - Train Accuracy: 0.5156, Validation Accuracy: 0.4497, Loss: 1.1731\n",
      "Epoch   1 Batch 1260/2109 - Train Accuracy: 0.5960, Validation Accuracy: 0.4740, Loss: 1.0304\n",
      "Epoch   1 Batch 1270/2109 - Train Accuracy: 0.6335, Validation Accuracy: 0.4965, Loss: 0.8309\n",
      "Epoch   1 Batch 1280/2109 - Train Accuracy: 0.5531, Validation Accuracy: 0.4566, Loss: 1.1158\n",
      "Epoch   1 Batch 1290/2109 - Train Accuracy: 0.4766, Validation Accuracy: 0.4601, Loss: 1.4524\n",
      "Epoch   1 Batch 1300/2109 - Train Accuracy: 0.6974, Validation Accuracy: 0.4688, Loss: 0.7526\n",
      "Epoch   1 Batch 1310/2109 - Train Accuracy: 0.5911, Validation Accuracy: 0.4653, Loss: 1.0204\n",
      "Epoch   1 Batch 1320/2109 - Train Accuracy: 0.6293, Validation Accuracy: 0.4878, Loss: 0.8573\n",
      "Epoch   1 Batch 1330/2109 - Train Accuracy: 0.5404, Validation Accuracy: 0.4826, Loss: 1.1433\n",
      "Epoch   1 Batch 1340/2109 - Train Accuracy: 0.3785, Validation Accuracy: 0.4826, Loss: 1.2778\n",
      "Epoch   1 Batch 1350/2109 - Train Accuracy: 0.4703, Validation Accuracy: 0.5434, Loss: 1.2463\n",
      "Epoch   1 Batch 1360/2109 - Train Accuracy: 0.4587, Validation Accuracy: 0.6111, Loss: 1.0381\n",
      "Epoch   1 Batch 1370/2109 - Train Accuracy: 0.6384, Validation Accuracy: 0.6372, Loss: 0.8441\n",
      "Epoch   1 Batch 1380/2109 - Train Accuracy: 0.5893, Validation Accuracy: 0.6163, Loss: 1.1433\n",
      "Epoch   1 Batch 1390/2109 - Train Accuracy: 0.5713, Validation Accuracy: 0.6024, Loss: 0.9822\n",
      "Epoch   1 Batch 1400/2109 - Train Accuracy: 0.7130, Validation Accuracy: 0.5000, Loss: 0.5660\n",
      "Epoch   1 Batch 1410/2109 - Train Accuracy: 0.6198, Validation Accuracy: 0.4705, Loss: 0.7239\n",
      "Epoch   1 Batch 1420/2109 - Train Accuracy: 0.6172, Validation Accuracy: 0.4913, Loss: 0.8070\n",
      "Epoch   1 Batch 1430/2109 - Train Accuracy: 0.6349, Validation Accuracy: 0.4670, Loss: 0.7590\n",
      "Epoch   1 Batch 1440/2109 - Train Accuracy: 0.5625, Validation Accuracy: 0.5069, Loss: 0.9663\n",
      "Epoch   1 Batch 1450/2109 - Train Accuracy: 0.7057, Validation Accuracy: 0.5156, Loss: 0.6670\n",
      "Epoch   1 Batch 1460/2109 - Train Accuracy: 0.5739, Validation Accuracy: 0.5104, Loss: 0.9300\n",
      "Epoch   1 Batch 1470/2109 - Train Accuracy: 0.5951, Validation Accuracy: 0.4670, Loss: 0.7870\n",
      "Epoch   1 Batch 1480/2109 - Train Accuracy: 0.5413, Validation Accuracy: 0.4965, Loss: 1.0443\n",
      "Epoch   1 Batch 1490/2109 - Train Accuracy: 0.6903, Validation Accuracy: 0.4913, Loss: 0.7380\n",
      "Epoch   1 Batch 1500/2109 - Train Accuracy: 0.6510, Validation Accuracy: 0.5399, Loss: 0.7373\n",
      "Epoch   1 Batch 1510/2109 - Train Accuracy: 0.5977, Validation Accuracy: 0.5295, Loss: 0.9665\n",
      "Epoch   1 Batch 1520/2109 - Train Accuracy: 0.4896, Validation Accuracy: 0.5122, Loss: 1.3289\n",
      "Epoch   1 Batch 1530/2109 - Train Accuracy: 0.6984, Validation Accuracy: 0.4722, Loss: 0.8174\n",
      "Epoch   1 Batch 1540/2109 - Train Accuracy: 0.7014, Validation Accuracy: 0.4740, Loss: 0.7814\n",
      "Epoch   1 Batch 1550/2109 - Train Accuracy: 0.5000, Validation Accuracy: 0.5000, Loss: 0.9830\n",
      "Epoch   1 Batch 1560/2109 - Train Accuracy: 0.6683, Validation Accuracy: 0.4826, Loss: 0.7829\n",
      "Epoch   1 Batch 1570/2109 - Train Accuracy: 0.6154, Validation Accuracy: 0.5330, Loss: 0.7399\n",
      "Epoch   1 Batch 1580/2109 - Train Accuracy: 0.6442, Validation Accuracy: 0.5312, Loss: 0.8142\n",
      "Epoch   1 Batch 1590/2109 - Train Accuracy: 0.6763, Validation Accuracy: 0.5382, Loss: 0.7548\n",
      "Epoch   1 Batch 1600/2109 - Train Accuracy: 0.5344, Validation Accuracy: 0.4913, Loss: 0.8152\n",
      "Epoch   1 Batch 1610/2109 - Train Accuracy: 0.6219, Validation Accuracy: 0.4618, Loss: 0.9683\n",
      "Epoch   1 Batch 1620/2109 - Train Accuracy: 0.6068, Validation Accuracy: 0.4531, Loss: 0.9240\n",
      "Epoch   1 Batch 1630/2109 - Train Accuracy: 0.6806, Validation Accuracy: 0.4653, Loss: 0.8036\n",
      "Epoch   1 Batch 1640/2109 - Train Accuracy: 0.6462, Validation Accuracy: 0.4531, Loss: 0.8576\n",
      "Epoch   1 Batch 1650/2109 - Train Accuracy: 0.7096, Validation Accuracy: 0.4514, Loss: 0.6800\n",
      "Epoch   1 Batch 1660/2109 - Train Accuracy: 0.6992, Validation Accuracy: 0.4774, Loss: 0.7046\n",
      "Epoch   1 Batch 1670/2109 - Train Accuracy: 0.4271, Validation Accuracy: 0.5312, Loss: 1.5447\n",
      "Epoch   1 Batch 1680/2109 - Train Accuracy: 0.3679, Validation Accuracy: 0.5451, Loss: 0.9948\n",
      "Epoch   1 Batch 1690/2109 - Train Accuracy: 0.6430, Validation Accuracy: 0.4774, Loss: 0.7524\n",
      "Epoch   1 Batch 1700/2109 - Train Accuracy: 0.6270, Validation Accuracy: 0.4653, Loss: 0.7897\n",
      "Epoch   1 Batch 1710/2109 - Train Accuracy: 0.5297, Validation Accuracy: 0.4462, Loss: 1.1512\n",
      "Epoch   1 Batch 1720/2109 - Train Accuracy: 0.6932, Validation Accuracy: 0.4722, Loss: 0.7808\n",
      "Epoch   1 Batch 1730/2109 - Train Accuracy: 0.5062, Validation Accuracy: 0.4878, Loss: 0.8928\n",
      "Epoch   1 Batch 1740/2109 - Train Accuracy: 0.5114, Validation Accuracy: 0.4896, Loss: 0.8139\n",
      "Epoch   1 Batch 1750/2109 - Train Accuracy: 0.7170, Validation Accuracy: 0.4722, Loss: 0.7195\n",
      "Epoch   1 Batch 1760/2109 - Train Accuracy: 0.7688, Validation Accuracy: 0.4670, Loss: 0.6435\n",
      "Epoch   1 Batch 1770/2109 - Train Accuracy: 0.7212, Validation Accuracy: 0.4670, Loss: 0.7371\n",
      "Epoch   1 Batch 1780/2109 - Train Accuracy: 0.6548, Validation Accuracy: 0.4688, Loss: 0.7242\n",
      "Epoch   1 Batch 1790/2109 - Train Accuracy: 0.5483, Validation Accuracy: 0.4948, Loss: 1.0027\n",
      "Epoch   1 Batch 1800/2109 - Train Accuracy: 0.7151, Validation Accuracy: 0.4896, Loss: 0.6448\n",
      "Epoch   1 Batch 1810/2109 - Train Accuracy: 0.8359, Validation Accuracy: 0.4965, Loss: 0.4064\n",
      "Epoch   1 Batch 1820/2109 - Train Accuracy: 0.6574, Validation Accuracy: 0.5191, Loss: 0.7194\n",
      "Epoch   1 Batch 1830/2109 - Train Accuracy: 0.4431, Validation Accuracy: 0.4965, Loss: 1.1309\n",
      "Epoch   1 Batch 1840/2109 - Train Accuracy: 0.5547, Validation Accuracy: 0.5052, Loss: 1.0590\n",
      "Epoch   1 Batch 1850/2109 - Train Accuracy: 0.4359, Validation Accuracy: 0.4878, Loss: 0.8279\n",
      "Epoch   1 Batch 1860/2109 - Train Accuracy: 0.6589, Validation Accuracy: 0.4531, Loss: 0.8074\n",
      "Epoch   1 Batch 1870/2109 - Train Accuracy: 0.7260, Validation Accuracy: 0.5104, Loss: 0.7207\n",
      "Epoch   1 Batch 1880/2109 - Train Accuracy: 0.6293, Validation Accuracy: 0.5590, Loss: 0.7039\n",
      "Epoch   1 Batch 1890/2109 - Train Accuracy: 0.6109, Validation Accuracy: 0.6007, Loss: 0.9210\n",
      "Epoch   1 Batch 1900/2109 - Train Accuracy: 0.7216, Validation Accuracy: 0.5781, Loss: 0.5826\n",
      "Epoch   1 Batch 1910/2109 - Train Accuracy: 0.6625, Validation Accuracy: 0.5833, Loss: 0.8473\n",
      "Epoch   1 Batch 1920/2109 - Train Accuracy: 0.6354, Validation Accuracy: 0.6007, Loss: 0.7995\n",
      "Epoch   1 Batch 1930/2109 - Train Accuracy: 0.7812, Validation Accuracy: 0.5868, Loss: 0.5342\n",
      "Epoch   1 Batch 1940/2109 - Train Accuracy: 0.5043, Validation Accuracy: 0.5729, Loss: 0.8423\n",
      "Epoch   1 Batch 1950/2109 - Train Accuracy: 0.4591, Validation Accuracy: 0.5799, Loss: 1.2079\n",
      "Epoch   1 Batch 1960/2109 - Train Accuracy: 0.4813, Validation Accuracy: 0.5903, Loss: 1.1340\n",
      "Epoch   1 Batch 1970/2109 - Train Accuracy: 0.5219, Validation Accuracy: 0.6042, Loss: 0.9712\n",
      "Epoch   1 Batch 1980/2109 - Train Accuracy: 0.2865, Validation Accuracy: 0.5503, Loss: 1.1389\n",
      "Epoch   1 Batch 1990/2109 - Train Accuracy: 0.6589, Validation Accuracy: 0.5573, Loss: 0.7192\n",
      "Epoch   1 Batch 2000/2109 - Train Accuracy: 0.6901, Validation Accuracy: 0.5642, Loss: 0.8094\n",
      "Epoch   1 Batch 2010/2109 - Train Accuracy: 0.6594, Validation Accuracy: 0.5573, Loss: 0.6769\n",
      "Epoch   1 Batch 2020/2109 - Train Accuracy: 0.7109, Validation Accuracy: 0.4844, Loss: 0.7156\n",
      "Epoch   1 Batch 2030/2109 - Train Accuracy: 0.5920, Validation Accuracy: 0.4375, Loss: 0.9014\n",
      "Epoch   1 Batch 2040/2109 - Train Accuracy: 0.7740, Validation Accuracy: 0.4792, Loss: 0.6086\n",
      "Epoch   1 Batch 2050/2109 - Train Accuracy: 0.4969, Validation Accuracy: 0.4757, Loss: 0.9391\n",
      "Epoch   1 Batch 2060/2109 - Train Accuracy: 0.8313, Validation Accuracy: 0.4653, Loss: 0.5874\n",
      "Epoch   1 Batch 2070/2109 - Train Accuracy: 0.6432, Validation Accuracy: 0.4566, Loss: 0.9039\n",
      "Epoch   1 Batch 2080/2109 - Train Accuracy: 0.7469, Validation Accuracy: 0.4844, Loss: 0.5672\n",
      "Epoch   1 Batch 2090/2109 - Train Accuracy: 0.5174, Validation Accuracy: 0.4531, Loss: 1.0396\n",
      "Epoch   1 Batch 2100/2109 - Train Accuracy: 0.8584, Validation Accuracy: 0.4618, Loss: 0.3743\n",
      "Epoch   2 Batch   10/2109 - Train Accuracy: 0.5709, Validation Accuracy: 0.4253, Loss: 0.8285\n",
      "Epoch   2 Batch   20/2109 - Train Accuracy: 0.4362, Validation Accuracy: 0.5226, Loss: 1.1730\n",
      "Epoch   2 Batch   30/2109 - Train Accuracy: 0.6319, Validation Accuracy: 0.5556, Loss: 0.8063\n",
      "Epoch   2 Batch   40/2109 - Train Accuracy: 0.6029, Validation Accuracy: 0.6233, Loss: 0.8767\n",
      "Epoch   2 Batch   50/2109 - Train Accuracy: 0.6813, Validation Accuracy: 0.6267, Loss: 0.8140\n",
      "Epoch   2 Batch   60/2109 - Train Accuracy: 0.6510, Validation Accuracy: 0.6719, Loss: 0.7637\n",
      "Epoch   2 Batch   70/2109 - Train Accuracy: 0.5879, Validation Accuracy: 0.6250, Loss: 0.9611\n",
      "Epoch   2 Batch   80/2109 - Train Accuracy: 0.4781, Validation Accuracy: 0.6736, Loss: 0.9899\n",
      "Epoch   2 Batch   90/2109 - Train Accuracy: 0.4484, Validation Accuracy: 0.6510, Loss: 1.1975\n",
      "Epoch   2 Batch  100/2109 - Train Accuracy: 0.6647, Validation Accuracy: 0.6858, Loss: 0.7678\n",
      "Epoch   2 Batch  110/2109 - Train Accuracy: 0.4757, Validation Accuracy: 0.6806, Loss: 1.1277\n",
      "Epoch   2 Batch  120/2109 - Train Accuracy: 0.6927, Validation Accuracy: 0.6615, Loss: 0.6911\n",
      "Epoch   2 Batch  130/2109 - Train Accuracy: 0.7212, Validation Accuracy: 0.5243, Loss: 0.6644\n",
      "Epoch   2 Batch  140/2109 - Train Accuracy: 0.6534, Validation Accuracy: 0.5052, Loss: 0.7890\n",
      "Epoch   2 Batch  150/2109 - Train Accuracy: 0.6667, Validation Accuracy: 0.4878, Loss: 0.8330\n",
      "Epoch   2 Batch  160/2109 - Train Accuracy: 0.7141, Validation Accuracy: 0.5069, Loss: 0.7683\n",
      "Epoch   2 Batch  170/2109 - Train Accuracy: 0.5057, Validation Accuracy: 0.4878, Loss: 0.6879\n",
      "Epoch   2 Batch  180/2109 - Train Accuracy: 0.7902, Validation Accuracy: 0.4844, Loss: 0.4423\n",
      "Epoch   2 Batch  190/2109 - Train Accuracy: 0.7320, Validation Accuracy: 0.5000, Loss: 0.6804\n",
      "Epoch   2 Batch  200/2109 - Train Accuracy: 0.5312, Validation Accuracy: 0.5538, Loss: 0.8112\n",
      "Epoch   2 Batch  210/2109 - Train Accuracy: 0.6859, Validation Accuracy: 0.5174, Loss: 0.8662\n",
      "Epoch   2 Batch  220/2109 - Train Accuracy: 0.7257, Validation Accuracy: 0.4844, Loss: 0.6483\n",
      "Epoch   2 Batch  230/2109 - Train Accuracy: 0.7539, Validation Accuracy: 0.5521, Loss: 0.6640\n",
      "Epoch   2 Batch  240/2109 - Train Accuracy: 0.7543, Validation Accuracy: 0.5885, Loss: 0.5678\n",
      "Epoch   2 Batch  250/2109 - Train Accuracy: 0.5384, Validation Accuracy: 0.5503, Loss: 0.8758\n",
      "Epoch   2 Batch  260/2109 - Train Accuracy: 0.4422, Validation Accuracy: 0.5330, Loss: 0.5705\n",
      "Epoch   2 Batch  270/2109 - Train Accuracy: 0.6966, Validation Accuracy: 0.4948, Loss: 0.8281\n",
      "Epoch   2 Batch  280/2109 - Train Accuracy: 0.7096, Validation Accuracy: 0.5000, Loss: 0.6028\n",
      "Epoch   2 Batch  290/2109 - Train Accuracy: 0.6547, Validation Accuracy: 0.4774, Loss: 0.6620\n",
      "Epoch   2 Batch  300/2109 - Train Accuracy: 0.6886, Validation Accuracy: 0.4861, Loss: 0.6920\n",
      "Epoch   2 Batch  310/2109 - Train Accuracy: 0.5589, Validation Accuracy: 0.5677, Loss: 0.9362\n",
      "Epoch   2 Batch  320/2109 - Train Accuracy: 0.6108, Validation Accuracy: 0.5938, Loss: 0.8047\n",
      "Epoch   2 Batch  330/2109 - Train Accuracy: 0.7326, Validation Accuracy: 0.6233, Loss: 0.6669\n",
      "Epoch   2 Batch  340/2109 - Train Accuracy: 0.6250, Validation Accuracy: 0.5851, Loss: 0.7693\n",
      "Epoch   2 Batch  350/2109 - Train Accuracy: 0.6844, Validation Accuracy: 0.5226, Loss: 0.8251\n",
      "Epoch   2 Batch  360/2109 - Train Accuracy: 0.6138, Validation Accuracy: 0.4983, Loss: 0.6366\n",
      "Epoch   2 Batch  370/2109 - Train Accuracy: 0.5836, Validation Accuracy: 0.4705, Loss: 0.7986\n",
      "Epoch   2 Batch  380/2109 - Train Accuracy: 0.5604, Validation Accuracy: 0.4670, Loss: 0.8379\n",
      "Epoch   2 Batch  390/2109 - Train Accuracy: 0.6504, Validation Accuracy: 0.4566, Loss: 0.5572\n",
      "Epoch   2 Batch  400/2109 - Train Accuracy: 0.6395, Validation Accuracy: 0.4601, Loss: 0.6129\n",
      "Epoch   2 Batch  410/2109 - Train Accuracy: 0.7118, Validation Accuracy: 0.4722, Loss: 0.6384\n",
      "Epoch   2 Batch  420/2109 - Train Accuracy: 0.7331, Validation Accuracy: 0.5365, Loss: 0.6482\n",
      "Epoch   2 Batch  430/2109 - Train Accuracy: 0.5156, Validation Accuracy: 0.5156, Loss: 0.8733\n",
      "Epoch   2 Batch  440/2109 - Train Accuracy: 0.6946, Validation Accuracy: 0.4965, Loss: 0.7453\n",
      "Epoch   2 Batch  450/2109 - Train Accuracy: 0.7273, Validation Accuracy: 0.5660, Loss: 0.6328\n",
      "Epoch   2 Batch  460/2109 - Train Accuracy: 0.8192, Validation Accuracy: 0.5920, Loss: 0.4103\n",
      "Epoch   2 Batch  470/2109 - Train Accuracy: 0.6690, Validation Accuracy: 0.5226, Loss: 0.7816\n",
      "Epoch   2 Batch  480/2109 - Train Accuracy: 0.6382, Validation Accuracy: 0.5590, Loss: 0.7188\n",
      "Epoch   2 Batch  490/2109 - Train Accuracy: 0.6875, Validation Accuracy: 0.5608, Loss: 0.7089\n",
      "Epoch   2 Batch  500/2109 - Train Accuracy: 0.6576, Validation Accuracy: 0.5538, Loss: 0.8607\n",
      "Epoch   2 Batch  510/2109 - Train Accuracy: 0.6149, Validation Accuracy: 0.5694, Loss: 0.7838\n",
      "Epoch   2 Batch  520/2109 - Train Accuracy: 0.6885, Validation Accuracy: 0.5712, Loss: 0.6111\n",
      "Epoch   2 Batch  530/2109 - Train Accuracy: 0.7656, Validation Accuracy: 0.5694, Loss: 0.5916\n",
      "Epoch   2 Batch  540/2109 - Train Accuracy: 0.8026, Validation Accuracy: 0.5868, Loss: 0.5271\n",
      "Epoch   2 Batch  550/2109 - Train Accuracy: 0.6656, Validation Accuracy: 0.5799, Loss: 0.7578\n",
      "Epoch   2 Batch  560/2109 - Train Accuracy: 0.3646, Validation Accuracy: 0.5573, Loss: 1.1146\n",
      "Epoch   2 Batch  570/2109 - Train Accuracy: 0.7529, Validation Accuracy: 0.6545, Loss: 0.4861\n",
      "Epoch   2 Batch  580/2109 - Train Accuracy: 0.8151, Validation Accuracy: 0.6615, Loss: 0.5798\n",
      "Epoch   2 Batch  590/2109 - Train Accuracy: 0.6382, Validation Accuracy: 0.6701, Loss: 0.8195\n",
      "Epoch   2 Batch  600/2109 - Train Accuracy: 0.6406, Validation Accuracy: 0.6441, Loss: 0.7268\n",
      "Epoch   2 Batch  610/2109 - Train Accuracy: 0.6992, Validation Accuracy: 0.6840, Loss: 0.5974\n",
      "Epoch   2 Batch  620/2109 - Train Accuracy: 0.7383, Validation Accuracy: 0.6875, Loss: 0.6536\n",
      "Epoch   2 Batch  630/2109 - Train Accuracy: 0.6833, Validation Accuracy: 0.6181, Loss: 0.5535\n",
      "Epoch   2 Batch  640/2109 - Train Accuracy: 0.6628, Validation Accuracy: 0.6597, Loss: 0.7983\n",
      "Epoch   2 Batch  650/2109 - Train Accuracy: 0.7484, Validation Accuracy: 0.6128, Loss: 0.5100\n",
      "Epoch   2 Batch  660/2109 - Train Accuracy: 0.6891, Validation Accuracy: 0.5677, Loss: 0.5869\n",
      "Epoch   2 Batch  670/2109 - Train Accuracy: 0.7227, Validation Accuracy: 0.5191, Loss: 0.5701\n",
      "Epoch   2 Batch  680/2109 - Train Accuracy: 0.7043, Validation Accuracy: 0.5226, Loss: 0.5903\n",
      "Epoch   2 Batch  690/2109 - Train Accuracy: 0.7512, Validation Accuracy: 0.5000, Loss: 0.5026\n",
      "Epoch   2 Batch  700/2109 - Train Accuracy: 0.7756, Validation Accuracy: 0.5660, Loss: 0.5973\n",
      "Epoch   2 Batch  710/2109 - Train Accuracy: 0.6335, Validation Accuracy: 0.5885, Loss: 0.8975\n",
      "Epoch   2 Batch  720/2109 - Train Accuracy: 0.6312, Validation Accuracy: 0.5608, Loss: 0.7767\n",
      "Epoch   2 Batch  730/2109 - Train Accuracy: 0.6934, Validation Accuracy: 0.5868, Loss: 0.7411\n",
      "Epoch   2 Batch  740/2109 - Train Accuracy: 0.4792, Validation Accuracy: 0.6771, Loss: 1.1061\n",
      "Epoch   2 Batch  750/2109 - Train Accuracy: 0.7669, Validation Accuracy: 0.6684, Loss: 0.5289\n",
      "Epoch   2 Batch  760/2109 - Train Accuracy: 0.6094, Validation Accuracy: 0.6354, Loss: 0.9361\n",
      "Epoch   2 Batch  770/2109 - Train Accuracy: 0.8125, Validation Accuracy: 0.6250, Loss: 0.4123\n",
      "Epoch   2 Batch  780/2109 - Train Accuracy: 0.8558, Validation Accuracy: 0.6076, Loss: 0.4051\n",
      "Epoch   2 Batch  790/2109 - Train Accuracy: 0.7937, Validation Accuracy: 0.6059, Loss: 0.4701\n",
      "Epoch   2 Batch  800/2109 - Train Accuracy: 0.7827, Validation Accuracy: 0.6528, Loss: 0.5349\n",
      "Epoch   2 Batch  810/2109 - Train Accuracy: 0.6922, Validation Accuracy: 0.4722, Loss: 0.8127\n",
      "Epoch   2 Batch  820/2109 - Train Accuracy: 0.8764, Validation Accuracy: 0.4358, Loss: 0.3547\n",
      "Epoch   2 Batch  830/2109 - Train Accuracy: 0.8328, Validation Accuracy: 0.3993, Loss: 0.3906\n",
      "Epoch   2 Batch  840/2109 - Train Accuracy: 0.7074, Validation Accuracy: 0.4236, Loss: 0.5675\n",
      "Epoch   2 Batch  850/2109 - Train Accuracy: 0.7859, Validation Accuracy: 0.4531, Loss: 0.5972\n",
      "Epoch   2 Batch  860/2109 - Train Accuracy: 0.6429, Validation Accuracy: 0.4201, Loss: 0.7002\n",
      "Epoch   2 Batch  870/2109 - Train Accuracy: 0.7000, Validation Accuracy: 0.4670, Loss: 0.6851\n",
      "Epoch   2 Batch  880/2109 - Train Accuracy: 0.5838, Validation Accuracy: 0.4149, Loss: 1.0161\n",
      "Epoch   2 Batch  890/2109 - Train Accuracy: 0.7125, Validation Accuracy: 0.4219, Loss: 0.5534\n",
      "Epoch   2 Batch  900/2109 - Train Accuracy: 0.4931, Validation Accuracy: 0.4323, Loss: 0.5474\n",
      "Epoch   2 Batch  910/2109 - Train Accuracy: 0.5966, Validation Accuracy: 0.4306, Loss: 0.8106\n",
      "Epoch   2 Batch  920/2109 - Train Accuracy: 0.5960, Validation Accuracy: 0.4566, Loss: 0.8445\n",
      "Epoch   2 Batch  930/2109 - Train Accuracy: 0.6417, Validation Accuracy: 0.4809, Loss: 0.7276\n",
      "Epoch   2 Batch  940/2109 - Train Accuracy: 0.6201, Validation Accuracy: 0.4861, Loss: 0.7422\n",
      "Epoch   2 Batch  950/2109 - Train Accuracy: 0.6625, Validation Accuracy: 0.4861, Loss: 0.5244\n",
      "Epoch   2 Batch  960/2109 - Train Accuracy: 0.6607, Validation Accuracy: 0.5538, Loss: 0.7270\n",
      "Epoch   2 Batch  970/2109 - Train Accuracy: 0.7786, Validation Accuracy: 0.5347, Loss: 0.4717\n",
      "Epoch   2 Batch  980/2109 - Train Accuracy: 0.6830, Validation Accuracy: 0.4878, Loss: 0.5159\n",
      "Epoch   2 Batch  990/2109 - Train Accuracy: 0.7670, Validation Accuracy: 0.4774, Loss: 0.6121\n",
      "Epoch   2 Batch 1000/2109 - Train Accuracy: 0.8651, Validation Accuracy: 0.6076, Loss: 0.3780\n",
      "Epoch   2 Batch 1010/2109 - Train Accuracy: 0.7514, Validation Accuracy: 0.6267, Loss: 0.6279\n",
      "Epoch   2 Batch 1020/2109 - Train Accuracy: 0.6962, Validation Accuracy: 0.6319, Loss: 0.5276\n",
      "Epoch   2 Batch 1030/2109 - Train Accuracy: 0.6790, Validation Accuracy: 0.6111, Loss: 0.5760\n",
      "Epoch   2 Batch 1040/2109 - Train Accuracy: 0.8040, Validation Accuracy: 0.5521, Loss: 0.4740\n",
      "Epoch   2 Batch 1050/2109 - Train Accuracy: 0.6562, Validation Accuracy: 0.6042, Loss: 0.5967\n",
      "Epoch   2 Batch 1060/2109 - Train Accuracy: 0.7827, Validation Accuracy: 0.5590, Loss: 0.4800\n",
      "Epoch   2 Batch 1070/2109 - Train Accuracy: 0.8438, Validation Accuracy: 0.5642, Loss: 0.4342\n",
      "Epoch   2 Batch 1080/2109 - Train Accuracy: 0.7240, Validation Accuracy: 0.6389, Loss: 0.6698\n",
      "Epoch   2 Batch 1090/2109 - Train Accuracy: 0.6672, Validation Accuracy: 0.6441, Loss: 0.7753\n",
      "Epoch   2 Batch 1100/2109 - Train Accuracy: 0.7383, Validation Accuracy: 0.6493, Loss: 0.6372\n",
      "Epoch   2 Batch 1110/2109 - Train Accuracy: 0.7669, Validation Accuracy: 0.6441, Loss: 0.4586\n",
      "Epoch   2 Batch 1120/2109 - Train Accuracy: 0.7031, Validation Accuracy: 0.6406, Loss: 0.7240\n",
      "Epoch   2 Batch 1130/2109 - Train Accuracy: 0.7396, Validation Accuracy: 0.6545, Loss: 0.5985\n",
      "Epoch   2 Batch 1140/2109 - Train Accuracy: 0.5169, Validation Accuracy: 0.6354, Loss: 1.0251\n",
      "Epoch   2 Batch 1150/2109 - Train Accuracy: 0.6107, Validation Accuracy: 0.7031, Loss: 0.6993\n",
      "Epoch   2 Batch 1160/2109 - Train Accuracy: 0.8438, Validation Accuracy: 0.6910, Loss: 0.3718\n",
      "Epoch   2 Batch 1170/2109 - Train Accuracy: 0.7234, Validation Accuracy: 0.7205, Loss: 0.5346\n",
      "Epoch   2 Batch 1180/2109 - Train Accuracy: 0.7545, Validation Accuracy: 0.7257, Loss: 0.4415\n",
      "Epoch   2 Batch 1190/2109 - Train Accuracy: 0.8111, Validation Accuracy: 0.7396, Loss: 0.5660\n",
      "Epoch   2 Batch 1200/2109 - Train Accuracy: 0.5923, Validation Accuracy: 0.6806, Loss: 0.5910\n",
      "Epoch   2 Batch 1210/2109 - Train Accuracy: 0.7201, Validation Accuracy: 0.7135, Loss: 0.5661\n",
      "Epoch   2 Batch 1220/2109 - Train Accuracy: 0.7333, Validation Accuracy: 0.6979, Loss: 0.5682\n",
      "Epoch   2 Batch 1230/2109 - Train Accuracy: 0.7292, Validation Accuracy: 0.6997, Loss: 0.6956\n",
      "Epoch   2 Batch 1240/2109 - Train Accuracy: 0.8040, Validation Accuracy: 0.7361, Loss: 0.4032\n",
      "Epoch   2 Batch 1250/2109 - Train Accuracy: 0.6031, Validation Accuracy: 0.6927, Loss: 0.8635\n",
      "Epoch   2 Batch 1260/2109 - Train Accuracy: 0.6964, Validation Accuracy: 0.7222, Loss: 0.6644\n",
      "Epoch   2 Batch 1270/2109 - Train Accuracy: 0.7670, Validation Accuracy: 0.7205, Loss: 0.5402\n",
      "Epoch   2 Batch 1280/2109 - Train Accuracy: 0.6719, Validation Accuracy: 0.6979, Loss: 0.7317\n",
      "Epoch   2 Batch 1290/2109 - Train Accuracy: 0.5609, Validation Accuracy: 0.6562, Loss: 0.9120\n",
      "Epoch   2 Batch 1300/2109 - Train Accuracy: 0.8168, Validation Accuracy: 0.6615, Loss: 0.4864\n",
      "Epoch   2 Batch 1310/2109 - Train Accuracy: 0.6706, Validation Accuracy: 0.6649, Loss: 0.7648\n",
      "Epoch   2 Batch 1320/2109 - Train Accuracy: 0.7273, Validation Accuracy: 0.6649, Loss: 0.6299\n",
      "Epoch   2 Batch 1330/2109 - Train Accuracy: 0.7214, Validation Accuracy: 0.6667, Loss: 0.7328\n",
      "Epoch   2 Batch 1340/2109 - Train Accuracy: 0.5712, Validation Accuracy: 0.6771, Loss: 0.7978\n",
      "Epoch   2 Batch 1350/2109 - Train Accuracy: 0.5797, Validation Accuracy: 0.6753, Loss: 0.7958\n",
      "Epoch   2 Batch 1360/2109 - Train Accuracy: 0.6328, Validation Accuracy: 0.6319, Loss: 0.7198\n",
      "Epoch   2 Batch 1370/2109 - Train Accuracy: 0.7701, Validation Accuracy: 0.6580, Loss: 0.5700\n",
      "Epoch   2 Batch 1380/2109 - Train Accuracy: 0.7567, Validation Accuracy: 0.6788, Loss: 0.6227\n",
      "Epoch   2 Batch 1390/2109 - Train Accuracy: 0.7598, Validation Accuracy: 0.6910, Loss: 0.5660\n",
      "Epoch   2 Batch 1400/2109 - Train Accuracy: 0.8010, Validation Accuracy: 0.6858, Loss: 0.3677\n",
      "Epoch   2 Batch 1410/2109 - Train Accuracy: 0.7695, Validation Accuracy: 0.6562, Loss: 0.5394\n",
      "Epoch   2 Batch 1420/2109 - Train Accuracy: 0.7865, Validation Accuracy: 0.6684, Loss: 0.4705\n",
      "Epoch   2 Batch 1430/2109 - Train Accuracy: 0.7884, Validation Accuracy: 0.6632, Loss: 0.4708\n",
      "Epoch   2 Batch 1440/2109 - Train Accuracy: 0.7312, Validation Accuracy: 0.7066, Loss: 0.5964\n",
      "Epoch   2 Batch 1450/2109 - Train Accuracy: 0.8229, Validation Accuracy: 0.6823, Loss: 0.4391\n",
      "Epoch   2 Batch 1460/2109 - Train Accuracy: 0.6790, Validation Accuracy: 0.6545, Loss: 0.5882\n",
      "Epoch   2 Batch 1470/2109 - Train Accuracy: 0.7109, Validation Accuracy: 0.6163, Loss: 0.4847\n",
      "Epoch   2 Batch 1480/2109 - Train Accuracy: 0.6719, Validation Accuracy: 0.6337, Loss: 0.6580\n",
      "Epoch   2 Batch 1490/2109 - Train Accuracy: 0.7699, Validation Accuracy: 0.6146, Loss: 0.4714\n",
      "Epoch   2 Batch 1500/2109 - Train Accuracy: 0.7375, Validation Accuracy: 0.6163, Loss: 0.4542\n",
      "Epoch   2 Batch 1510/2109 - Train Accuracy: 0.7057, Validation Accuracy: 0.6337, Loss: 0.6178\n",
      "Epoch   2 Batch 1520/2109 - Train Accuracy: 0.5820, Validation Accuracy: 0.6389, Loss: 0.7354\n",
      "Epoch   2 Batch 1530/2109 - Train Accuracy: 0.8016, Validation Accuracy: 0.6458, Loss: 0.5276\n",
      "Epoch   2 Batch 1540/2109 - Train Accuracy: 0.8281, Validation Accuracy: 0.6285, Loss: 0.4352\n",
      "Epoch   2 Batch 1550/2109 - Train Accuracy: 0.5948, Validation Accuracy: 0.6007, Loss: 0.6275\n",
      "Epoch   2 Batch 1560/2109 - Train Accuracy: 0.7031, Validation Accuracy: 0.5764, Loss: 0.5494\n",
      "Epoch   2 Batch 1570/2109 - Train Accuracy: 0.7728, Validation Accuracy: 0.6181, Loss: 0.4429\n",
      "Epoch   2 Batch 1580/2109 - Train Accuracy: 0.7224, Validation Accuracy: 0.6319, Loss: 0.5643\n",
      "Epoch   2 Batch 1590/2109 - Train Accuracy: 0.7455, Validation Accuracy: 0.6528, Loss: 0.4784\n",
      "Epoch   2 Batch 1600/2109 - Train Accuracy: 0.7453, Validation Accuracy: 0.6719, Loss: 0.4944\n",
      "Epoch   2 Batch 1610/2109 - Train Accuracy: 0.6859, Validation Accuracy: 0.6597, Loss: 0.6705\n",
      "Epoch   2 Batch 1620/2109 - Train Accuracy: 0.7240, Validation Accuracy: 0.6406, Loss: 0.5776\n",
      "Epoch   2 Batch 1630/2109 - Train Accuracy: 0.7326, Validation Accuracy: 0.6771, Loss: 0.4958\n",
      "Epoch   2 Batch 1640/2109 - Train Accuracy: 0.7612, Validation Accuracy: 0.6580, Loss: 0.5006\n",
      "Epoch   2 Batch 1650/2109 - Train Accuracy: 0.8620, Validation Accuracy: 0.6580, Loss: 0.3739\n",
      "Epoch   2 Batch 1660/2109 - Train Accuracy: 0.7917, Validation Accuracy: 0.6701, Loss: 0.5038\n",
      "Epoch   2 Batch 1670/2109 - Train Accuracy: 0.3767, Validation Accuracy: 0.6667, Loss: 1.0368\n",
      "Epoch   2 Batch 1680/2109 - Train Accuracy: 0.3565, Validation Accuracy: 0.6892, Loss: 0.7386\n",
      "Epoch   2 Batch 1690/2109 - Train Accuracy: 0.8137, Validation Accuracy: 0.6736, Loss: 0.4300\n",
      "Epoch   2 Batch 1700/2109 - Train Accuracy: 0.7676, Validation Accuracy: 0.6597, Loss: 0.5598\n",
      "Epoch   2 Batch 1710/2109 - Train Accuracy: 0.6781, Validation Accuracy: 0.6441, Loss: 0.7928\n",
      "Epoch   2 Batch 1720/2109 - Train Accuracy: 0.8040, Validation Accuracy: 0.6701, Loss: 0.4532\n",
      "Epoch   2 Batch 1730/2109 - Train Accuracy: 0.6922, Validation Accuracy: 0.6962, Loss: 0.5808\n",
      "Epoch   2 Batch 1740/2109 - Train Accuracy: 0.7315, Validation Accuracy: 0.7066, Loss: 0.4903\n",
      "Epoch   2 Batch 1750/2109 - Train Accuracy: 0.8576, Validation Accuracy: 0.6753, Loss: 0.3281\n",
      "Epoch   2 Batch 1760/2109 - Train Accuracy: 0.8656, Validation Accuracy: 0.6441, Loss: 0.3915\n",
      "Epoch   2 Batch 1770/2109 - Train Accuracy: 0.8053, Validation Accuracy: 0.6962, Loss: 0.4739\n",
      "Epoch   2 Batch 1780/2109 - Train Accuracy: 0.7884, Validation Accuracy: 0.7014, Loss: 0.3983\n",
      "Epoch   2 Batch 1790/2109 - Train Accuracy: 0.6648, Validation Accuracy: 0.6719, Loss: 0.6468\n",
      "Epoch   2 Batch 1800/2109 - Train Accuracy: 0.8113, Validation Accuracy: 0.6597, Loss: 0.4262\n",
      "Epoch   2 Batch 1810/2109 - Train Accuracy: 0.8893, Validation Accuracy: 0.6615, Loss: 0.2330\n",
      "Epoch   2 Batch 1820/2109 - Train Accuracy: 0.8304, Validation Accuracy: 0.6632, Loss: 0.3889\n",
      "Epoch   2 Batch 1830/2109 - Train Accuracy: 0.5469, Validation Accuracy: 0.6007, Loss: 0.8026\n",
      "Epoch   2 Batch 1840/2109 - Train Accuracy: 0.6477, Validation Accuracy: 0.6476, Loss: 0.7089\n",
      "Epoch   2 Batch 1850/2109 - Train Accuracy: 0.7719, Validation Accuracy: 0.6372, Loss: 0.4613\n",
      "Epoch   2 Batch 1860/2109 - Train Accuracy: 0.8229, Validation Accuracy: 0.6146, Loss: 0.4951\n",
      "Epoch   2 Batch 1870/2109 - Train Accuracy: 0.8053, Validation Accuracy: 0.6163, Loss: 0.4133\n",
      "Epoch   2 Batch 1880/2109 - Train Accuracy: 0.7344, Validation Accuracy: 0.6875, Loss: 0.4399\n",
      "Epoch   2 Batch 1890/2109 - Train Accuracy: 0.7266, Validation Accuracy: 0.7014, Loss: 0.5932\n",
      "Epoch   2 Batch 1900/2109 - Train Accuracy: 0.8381, Validation Accuracy: 0.7118, Loss: 0.3363\n",
      "Epoch   2 Batch 1910/2109 - Train Accuracy: 0.7125, Validation Accuracy: 0.7066, Loss: 0.6195\n",
      "Epoch   2 Batch 1920/2109 - Train Accuracy: 0.7188, Validation Accuracy: 0.6649, Loss: 0.5253\n",
      "Epoch   2 Batch 1930/2109 - Train Accuracy: 0.8707, Validation Accuracy: 0.6163, Loss: 0.2623\n",
      "Epoch   2 Batch 1940/2109 - Train Accuracy: 0.6918, Validation Accuracy: 0.6615, Loss: 0.4857\n",
      "Epoch   2 Batch 1950/2109 - Train Accuracy: 0.5625, Validation Accuracy: 0.6667, Loss: 0.7200\n",
      "Epoch   2 Batch 1960/2109 - Train Accuracy: 0.4927, Validation Accuracy: 0.6406, Loss: 0.7908\n",
      "Epoch   2 Batch 1970/2109 - Train Accuracy: 0.6438, Validation Accuracy: 0.6580, Loss: 0.6493\n",
      "Epoch   2 Batch 1980/2109 - Train Accuracy: 0.7031, Validation Accuracy: 0.6701, Loss: 0.7034\n",
      "Epoch   2 Batch 1990/2109 - Train Accuracy: 0.8125, Validation Accuracy: 0.6771, Loss: 0.4098\n",
      "Epoch   2 Batch 2000/2109 - Train Accuracy: 0.7943, Validation Accuracy: 0.6771, Loss: 0.5233\n",
      "Epoch   2 Batch 2010/2109 - Train Accuracy: 0.7375, Validation Accuracy: 0.6771, Loss: 0.4603\n",
      "Epoch   2 Batch 2020/2109 - Train Accuracy: 0.8438, Validation Accuracy: 0.6059, Loss: 0.4172\n",
      "Epoch   2 Batch 2030/2109 - Train Accuracy: 0.7378, Validation Accuracy: 0.5208, Loss: 0.6291\n",
      "Epoch   2 Batch 2040/2109 - Train Accuracy: 0.8329, Validation Accuracy: 0.5347, Loss: 0.3872\n",
      "Epoch   2 Batch 2050/2109 - Train Accuracy: 0.5375, Validation Accuracy: 0.5069, Loss: 0.5294\n",
      "Epoch   2 Batch 2060/2109 - Train Accuracy: 0.8828, Validation Accuracy: 0.4931, Loss: 0.3051\n",
      "Epoch   2 Batch 2070/2109 - Train Accuracy: 0.7643, Validation Accuracy: 0.5069, Loss: 0.6170\n",
      "Epoch   2 Batch 2080/2109 - Train Accuracy: 0.8031, Validation Accuracy: 0.5330, Loss: 0.4148\n",
      "Epoch   2 Batch 2090/2109 - Train Accuracy: 0.7240, Validation Accuracy: 0.5486, Loss: 0.6244\n",
      "Epoch   2 Batch 2100/2109 - Train Accuracy: 0.9111, Validation Accuracy: 0.5260, Loss: 0.2438\n",
      "Epoch   3 Batch   10/2109 - Train Accuracy: 0.6587, Validation Accuracy: 0.5712, Loss: 0.6224\n",
      "Epoch   3 Batch   20/2109 - Train Accuracy: 0.7435, Validation Accuracy: 0.6632, Loss: 0.5892\n",
      "Epoch   3 Batch   30/2109 - Train Accuracy: 0.7274, Validation Accuracy: 0.6997, Loss: 0.6646\n",
      "Epoch   3 Batch   40/2109 - Train Accuracy: 0.7214, Validation Accuracy: 0.7205, Loss: 0.5755\n",
      "Epoch   3 Batch   50/2109 - Train Accuracy: 0.7615, Validation Accuracy: 0.7344, Loss: 0.5076\n",
      "Epoch   3 Batch   60/2109 - Train Accuracy: 0.7344, Validation Accuracy: 0.7274, Loss: 0.5228\n",
      "Epoch   3 Batch   70/2109 - Train Accuracy: 0.6143, Validation Accuracy: 0.7031, Loss: 0.7097\n",
      "Epoch   3 Batch   80/2109 - Train Accuracy: 0.6375, Validation Accuracy: 0.7361, Loss: 0.7127\n",
      "Epoch   3 Batch   90/2109 - Train Accuracy: 0.5844, Validation Accuracy: 0.7049, Loss: 0.7658\n",
      "Epoch   3 Batch  100/2109 - Train Accuracy: 0.7416, Validation Accuracy: 0.7274, Loss: 0.5467\n",
      "Epoch   3 Batch  110/2109 - Train Accuracy: 0.6372, Validation Accuracy: 0.7274, Loss: 0.7071\n",
      "Epoch   3 Batch  120/2109 - Train Accuracy: 0.8411, Validation Accuracy: 0.7413, Loss: 0.3826\n",
      "Epoch   3 Batch  130/2109 - Train Accuracy: 0.8065, Validation Accuracy: 0.7309, Loss: 0.4123\n",
      "Epoch   3 Batch  140/2109 - Train Accuracy: 0.6889, Validation Accuracy: 0.7500, Loss: 0.6390\n",
      "Epoch   3 Batch  150/2109 - Train Accuracy: 0.6797, Validation Accuracy: 0.7361, Loss: 0.6484\n",
      "Epoch   3 Batch  160/2109 - Train Accuracy: 0.8234, Validation Accuracy: 0.7326, Loss: 0.4549\n",
      "Epoch   3 Batch  170/2109 - Train Accuracy: 0.7443, Validation Accuracy: 0.7344, Loss: 0.3648\n",
      "Epoch   3 Batch  180/2109 - Train Accuracy: 0.8549, Validation Accuracy: 0.7031, Loss: 0.2871\n",
      "Epoch   3 Batch  190/2109 - Train Accuracy: 0.8678, Validation Accuracy: 0.7292, Loss: 0.3430\n",
      "Epoch   3 Batch  200/2109 - Train Accuracy: 0.7937, Validation Accuracy: 0.7517, Loss: 0.4787\n",
      "Epoch   3 Batch  210/2109 - Train Accuracy: 0.7141, Validation Accuracy: 0.7535, Loss: 0.6697\n",
      "Epoch   3 Batch  220/2109 - Train Accuracy: 0.8333, Validation Accuracy: 0.7326, Loss: 0.4533\n",
      "Epoch   3 Batch  230/2109 - Train Accuracy: 0.7878, Validation Accuracy: 0.7413, Loss: 0.4248\n",
      "Epoch   3 Batch  240/2109 - Train Accuracy: 0.8537, Validation Accuracy: 0.7205, Loss: 0.3451\n",
      "Epoch   3 Batch  250/2109 - Train Accuracy: 0.7244, Validation Accuracy: 0.6997, Loss: 0.6097\n",
      "Epoch   3 Batch  260/2109 - Train Accuracy: 0.9000, Validation Accuracy: 0.7188, Loss: 0.2828\n",
      "Epoch   3 Batch  270/2109 - Train Accuracy: 0.7435, Validation Accuracy: 0.7274, Loss: 0.5420\n",
      "Epoch   3 Batch  280/2109 - Train Accuracy: 0.8242, Validation Accuracy: 0.7569, Loss: 0.3984\n",
      "Epoch   3 Batch  290/2109 - Train Accuracy: 0.8453, Validation Accuracy: 0.7448, Loss: 0.3836\n",
      "Epoch   3 Batch  300/2109 - Train Accuracy: 0.7757, Validation Accuracy: 0.7552, Loss: 0.5164\n",
      "Epoch   3 Batch  310/2109 - Train Accuracy: 0.6839, Validation Accuracy: 0.7517, Loss: 0.6607\n",
      "Epoch   3 Batch  320/2109 - Train Accuracy: 0.7770, Validation Accuracy: 0.7083, Loss: 0.5068\n",
      "Epoch   3 Batch  330/2109 - Train Accuracy: 0.7535, Validation Accuracy: 0.7222, Loss: 0.5634\n",
      "Epoch   3 Batch  340/2109 - Train Accuracy: 0.8113, Validation Accuracy: 0.7292, Loss: 0.4470\n",
      "Epoch   3 Batch  350/2109 - Train Accuracy: 0.7516, Validation Accuracy: 0.7500, Loss: 0.5821\n",
      "Epoch   3 Batch  360/2109 - Train Accuracy: 0.7500, Validation Accuracy: 0.7465, Loss: 0.4462\n",
      "Epoch   3 Batch  370/2109 - Train Accuracy: 0.6811, Validation Accuracy: 0.7344, Loss: 0.5018\n",
      "Epoch   3 Batch  380/2109 - Train Accuracy: 0.6760, Validation Accuracy: 0.7378, Loss: 0.5721\n",
      "Epoch   3 Batch  390/2109 - Train Accuracy: 0.7842, Validation Accuracy: 0.7309, Loss: 0.3561\n",
      "Epoch   3 Batch  400/2109 - Train Accuracy: 0.7165, Validation Accuracy: 0.7465, Loss: 0.4091\n",
      "Epoch   3 Batch  410/2109 - Train Accuracy: 0.7674, Validation Accuracy: 0.7292, Loss: 0.4489\n",
      "Epoch   3 Batch  420/2109 - Train Accuracy: 0.7695, Validation Accuracy: 0.7587, Loss: 0.5047\n",
      "Epoch   3 Batch  430/2109 - Train Accuracy: 0.5977, Validation Accuracy: 0.7587, Loss: 0.5997\n",
      "Epoch   3 Batch  440/2109 - Train Accuracy: 0.7983, Validation Accuracy: 0.7483, Loss: 0.4659\n",
      "Epoch   3 Batch  450/2109 - Train Accuracy: 0.8068, Validation Accuracy: 0.7274, Loss: 0.3620\n",
      "Epoch   3 Batch  460/2109 - Train Accuracy: 0.8627, Validation Accuracy: 0.7378, Loss: 0.2729\n",
      "Epoch   3 Batch  470/2109 - Train Accuracy: 0.7500, Validation Accuracy: 0.7413, Loss: 0.5250\n",
      "Epoch   3 Batch  480/2109 - Train Accuracy: 0.7692, Validation Accuracy: 0.7639, Loss: 0.4973\n",
      "Epoch   3 Batch  490/2109 - Train Accuracy: 0.7354, Validation Accuracy: 0.7483, Loss: 0.4823\n",
      "Epoch   3 Batch  500/2109 - Train Accuracy: 0.7253, Validation Accuracy: 0.7535, Loss: 0.6345\n",
      "Epoch   3 Batch  510/2109 - Train Accuracy: 0.6618, Validation Accuracy: 0.7552, Loss: 0.5776\n",
      "Epoch   3 Batch  520/2109 - Train Accuracy: 0.7958, Validation Accuracy: 0.7431, Loss: 0.3909\n",
      "Epoch   3 Batch  530/2109 - Train Accuracy: 0.8859, Validation Accuracy: 0.7517, Loss: 0.3840\n",
      "Epoch   3 Batch  540/2109 - Train Accuracy: 0.8338, Validation Accuracy: 0.7674, Loss: 0.3347\n",
      "Epoch   3 Batch  550/2109 - Train Accuracy: 0.7500, Validation Accuracy: 0.7500, Loss: 0.5473\n",
      "Epoch   3 Batch  560/2109 - Train Accuracy: 0.5365, Validation Accuracy: 0.7413, Loss: 0.7992\n",
      "Epoch   3 Batch  570/2109 - Train Accuracy: 0.7891, Validation Accuracy: 0.7222, Loss: 0.3315\n",
      "Epoch   3 Batch  580/2109 - Train Accuracy: 0.8867, Validation Accuracy: 0.7309, Loss: 0.3495\n",
      "Epoch   3 Batch  590/2109 - Train Accuracy: 0.6995, Validation Accuracy: 0.7535, Loss: 0.5800\n",
      "Epoch   3 Batch  600/2109 - Train Accuracy: 0.7221, Validation Accuracy: 0.7257, Loss: 0.5668\n",
      "Epoch   3 Batch  610/2109 - Train Accuracy: 0.7839, Validation Accuracy: 0.7396, Loss: 0.4219\n",
      "Epoch   3 Batch  620/2109 - Train Accuracy: 0.7917, Validation Accuracy: 0.7205, Loss: 0.5348\n",
      "Epoch   3 Batch  630/2109 - Train Accuracy: 0.7688, Validation Accuracy: 0.7188, Loss: 0.3936\n",
      "Epoch   3 Batch  640/2109 - Train Accuracy: 0.7565, Validation Accuracy: 0.7170, Loss: 0.5317\n",
      "Epoch   3 Batch  650/2109 - Train Accuracy: 0.8516, Validation Accuracy: 0.7326, Loss: 0.3179\n",
      "Epoch   3 Batch  660/2109 - Train Accuracy: 0.7844, Validation Accuracy: 0.7274, Loss: 0.3787\n",
      "Epoch   3 Batch  670/2109 - Train Accuracy: 0.7721, Validation Accuracy: 0.7240, Loss: 0.4380\n",
      "Epoch   3 Batch  680/2109 - Train Accuracy: 0.7704, Validation Accuracy: 0.7066, Loss: 0.4396\n",
      "Epoch   3 Batch  690/2109 - Train Accuracy: 0.7740, Validation Accuracy: 0.7135, Loss: 0.3288\n",
      "Epoch   3 Batch  700/2109 - Train Accuracy: 0.8366, Validation Accuracy: 0.6719, Loss: 0.3584\n",
      "Epoch   3 Batch  710/2109 - Train Accuracy: 0.6662, Validation Accuracy: 0.7240, Loss: 0.6726\n",
      "Epoch   3 Batch  720/2109 - Train Accuracy: 0.7859, Validation Accuracy: 0.7257, Loss: 0.4480\n",
      "Epoch   3 Batch  730/2109 - Train Accuracy: 0.7480, Validation Accuracy: 0.6910, Loss: 0.5486\n",
      "Epoch   3 Batch  740/2109 - Train Accuracy: 0.5807, Validation Accuracy: 0.7240, Loss: 0.7861\n",
      "Epoch   3 Batch  750/2109 - Train Accuracy: 0.8294, Validation Accuracy: 0.7031, Loss: 0.3807\n",
      "Epoch   3 Batch  760/2109 - Train Accuracy: 0.6108, Validation Accuracy: 0.6927, Loss: 0.7531\n",
      "Epoch   3 Batch  770/2109 - Train Accuracy: 0.8938, Validation Accuracy: 0.7049, Loss: 0.2813\n",
      "Epoch   3 Batch  780/2109 - Train Accuracy: 0.9014, Validation Accuracy: 0.7448, Loss: 0.2758\n",
      "Epoch   3 Batch  790/2109 - Train Accuracy: 0.9016, Validation Accuracy: 0.7083, Loss: 0.3069\n",
      "Epoch   3 Batch  800/2109 - Train Accuracy: 0.8807, Validation Accuracy: 0.7188, Loss: 0.3317\n",
      "Epoch   3 Batch  810/2109 - Train Accuracy: 0.6703, Validation Accuracy: 0.7483, Loss: 0.5592\n",
      "Epoch   3 Batch  820/2109 - Train Accuracy: 0.9190, Validation Accuracy: 0.6719, Loss: 0.2128\n",
      "Epoch   3 Batch  830/2109 - Train Accuracy: 0.8531, Validation Accuracy: 0.6146, Loss: 0.3137\n",
      "Epoch   3 Batch  840/2109 - Train Accuracy: 0.8082, Validation Accuracy: 0.5938, Loss: 0.3774\n",
      "Epoch   3 Batch  850/2109 - Train Accuracy: 0.8609, Validation Accuracy: 0.5399, Loss: 0.4143\n",
      "Epoch   3 Batch  860/2109 - Train Accuracy: 0.6797, Validation Accuracy: 0.5278, Loss: 0.5440\n",
      "Epoch   3 Batch  870/2109 - Train Accuracy: 0.8344, Validation Accuracy: 0.5382, Loss: 0.4012\n",
      "Epoch   3 Batch  880/2109 - Train Accuracy: 0.6250, Validation Accuracy: 0.5104, Loss: 0.8652\n",
      "Epoch   3 Batch  890/2109 - Train Accuracy: 0.7422, Validation Accuracy: 0.6024, Loss: 0.4321\n",
      "Epoch   3 Batch  900/2109 - Train Accuracy: 0.8576, Validation Accuracy: 0.6788, Loss: 0.3078\n",
      "Epoch   3 Batch  910/2109 - Train Accuracy: 0.7443, Validation Accuracy: 0.6302, Loss: 0.5941\n",
      "Epoch   3 Batch  920/2109 - Train Accuracy: 0.6429, Validation Accuracy: 0.6076, Loss: 0.6322\n",
      "Epoch   3 Batch  930/2109 - Train Accuracy: 0.7396, Validation Accuracy: 0.5469, Loss: 0.4877\n",
      "Epoch   3 Batch  940/2109 - Train Accuracy: 0.6895, Validation Accuracy: 0.5590, Loss: 0.4766\n",
      "Epoch   3 Batch  950/2109 - Train Accuracy: 0.7281, Validation Accuracy: 0.5486, Loss: 0.3967\n",
      "Epoch   3 Batch  960/2109 - Train Accuracy: 0.7288, Validation Accuracy: 0.5955, Loss: 0.5892\n",
      "Epoch   3 Batch  970/2109 - Train Accuracy: 0.8763, Validation Accuracy: 0.6528, Loss: 0.2742\n",
      "Epoch   3 Batch  980/2109 - Train Accuracy: 0.7433, Validation Accuracy: 0.6927, Loss: 0.3968\n",
      "Epoch   3 Batch  990/2109 - Train Accuracy: 0.8381, Validation Accuracy: 0.7014, Loss: 0.4573\n",
      "Epoch   3 Batch 1000/2109 - Train Accuracy: 0.8920, Validation Accuracy: 0.7413, Loss: 0.2742\n",
      "Epoch   3 Batch 1010/2109 - Train Accuracy: 0.7855, Validation Accuracy: 0.7535, Loss: 0.4566\n",
      "Epoch   3 Batch 1020/2109 - Train Accuracy: 0.8316, Validation Accuracy: 0.7587, Loss: 0.3635\n",
      "Epoch   3 Batch 1030/2109 - Train Accuracy: 0.8338, Validation Accuracy: 0.7361, Loss: 0.4010\n",
      "Epoch   3 Batch 1040/2109 - Train Accuracy: 0.8580, Validation Accuracy: 0.7118, Loss: 0.3387\n",
      "Epoch   3 Batch 1050/2109 - Train Accuracy: 0.7486, Validation Accuracy: 0.7170, Loss: 0.4242\n",
      "Epoch   3 Batch 1060/2109 - Train Accuracy: 0.8153, Validation Accuracy: 0.7153, Loss: 0.3156\n",
      "Epoch   3 Batch 1070/2109 - Train Accuracy: 0.8656, Validation Accuracy: 0.7153, Loss: 0.3315\n",
      "Epoch   3 Batch 1080/2109 - Train Accuracy: 0.8090, Validation Accuracy: 0.7326, Loss: 0.4461\n",
      "Epoch   3 Batch 1090/2109 - Train Accuracy: 0.6937, Validation Accuracy: 0.7292, Loss: 0.6346\n",
      "Epoch   3 Batch 1100/2109 - Train Accuracy: 0.7227, Validation Accuracy: 0.7569, Loss: 0.5163\n",
      "Epoch   3 Batch 1110/2109 - Train Accuracy: 0.8451, Validation Accuracy: 0.7517, Loss: 0.3291\n",
      "Epoch   3 Batch 1120/2109 - Train Accuracy: 0.7127, Validation Accuracy: 0.7535, Loss: 0.5302\n",
      "Epoch   3 Batch 1130/2109 - Train Accuracy: 0.8438, Validation Accuracy: 0.7274, Loss: 0.4056\n",
      "Epoch   3 Batch 1140/2109 - Train Accuracy: 0.5964, Validation Accuracy: 0.7517, Loss: 0.7114\n",
      "Epoch   3 Batch 1150/2109 - Train Accuracy: 0.7188, Validation Accuracy: 0.7483, Loss: 0.5236\n",
      "Epoch   3 Batch 1160/2109 - Train Accuracy: 0.8641, Validation Accuracy: 0.7257, Loss: 0.2487\n",
      "Epoch   3 Batch 1170/2109 - Train Accuracy: 0.8078, Validation Accuracy: 0.7326, Loss: 0.3801\n",
      "Epoch   3 Batch 1180/2109 - Train Accuracy: 0.8214, Validation Accuracy: 0.7587, Loss: 0.3532\n",
      "Epoch   3 Batch 1190/2109 - Train Accuracy: 0.8864, Validation Accuracy: 0.7483, Loss: 0.3510\n",
      "Epoch   3 Batch 1200/2109 - Train Accuracy: 0.7031, Validation Accuracy: 0.7135, Loss: 0.3675\n",
      "Epoch   3 Batch 1210/2109 - Train Accuracy: 0.8125, Validation Accuracy: 0.7188, Loss: 0.3804\n",
      "Epoch   3 Batch 1220/2109 - Train Accuracy: 0.8225, Validation Accuracy: 0.7257, Loss: 0.4043\n",
      "Epoch   3 Batch 1230/2109 - Train Accuracy: 0.7852, Validation Accuracy: 0.7378, Loss: 0.5257\n",
      "Epoch   3 Batch 1240/2109 - Train Accuracy: 0.8381, Validation Accuracy: 0.7465, Loss: 0.3117\n",
      "Epoch   3 Batch 1250/2109 - Train Accuracy: 0.6578, Validation Accuracy: 0.7344, Loss: 0.7162\n",
      "Epoch   3 Batch 1260/2109 - Train Accuracy: 0.7701, Validation Accuracy: 0.7431, Loss: 0.5013\n",
      "Epoch   3 Batch 1270/2109 - Train Accuracy: 0.8054, Validation Accuracy: 0.7517, Loss: 0.4116\n",
      "Epoch   3 Batch 1280/2109 - Train Accuracy: 0.7760, Validation Accuracy: 0.7326, Loss: 0.5026\n",
      "Epoch   3 Batch 1290/2109 - Train Accuracy: 0.7391, Validation Accuracy: 0.7326, Loss: 0.6001\n",
      "Epoch   3 Batch 1300/2109 - Train Accuracy: 0.8580, Validation Accuracy: 0.7344, Loss: 0.3033\n",
      "Epoch   3 Batch 1310/2109 - Train Accuracy: 0.7500, Validation Accuracy: 0.7378, Loss: 0.5679\n",
      "Epoch   3 Batch 1320/2109 - Train Accuracy: 0.7543, Validation Accuracy: 0.7517, Loss: 0.4981\n",
      "Epoch   3 Batch 1330/2109 - Train Accuracy: 0.7578, Validation Accuracy: 0.7639, Loss: 0.5142\n",
      "Epoch   3 Batch 1340/2109 - Train Accuracy: 0.6632, Validation Accuracy: 0.7604, Loss: 0.6260\n",
      "Epoch   3 Batch 1350/2109 - Train Accuracy: 0.7266, Validation Accuracy: 0.7014, Loss: 0.6152\n",
      "Epoch   3 Batch 1360/2109 - Train Accuracy: 0.6641, Validation Accuracy: 0.6719, Loss: 0.5577\n",
      "Epoch   3 Batch 1370/2109 - Train Accuracy: 0.8348, Validation Accuracy: 0.7361, Loss: 0.4472\n",
      "Epoch   3 Batch 1380/2109 - Train Accuracy: 0.8482, Validation Accuracy: 0.7309, Loss: 0.3947\n",
      "Epoch   3 Batch 1390/2109 - Train Accuracy: 0.7852, Validation Accuracy: 0.7222, Loss: 0.4225\n",
      "Epoch   3 Batch 1400/2109 - Train Accuracy: 0.8380, Validation Accuracy: 0.6858, Loss: 0.2685\n",
      "Epoch   3 Batch 1410/2109 - Train Accuracy: 0.8034, Validation Accuracy: 0.7014, Loss: 0.4452\n",
      "Epoch   3 Batch 1420/2109 - Train Accuracy: 0.8268, Validation Accuracy: 0.7500, Loss: 0.3577\n",
      "Epoch   3 Batch 1430/2109 - Train Accuracy: 0.8594, Validation Accuracy: 0.7222, Loss: 0.3037\n",
      "Epoch   3 Batch 1440/2109 - Train Accuracy: 0.7844, Validation Accuracy: 0.7326, Loss: 0.4694\n",
      "Epoch   3 Batch 1450/2109 - Train Accuracy: 0.8516, Validation Accuracy: 0.7431, Loss: 0.3343\n",
      "Epoch   3 Batch 1460/2109 - Train Accuracy: 0.7642, Validation Accuracy: 0.7361, Loss: 0.4220\n",
      "Epoch   3 Batch 1470/2109 - Train Accuracy: 0.7760, Validation Accuracy: 0.7083, Loss: 0.3499\n",
      "Epoch   3 Batch 1480/2109 - Train Accuracy: 0.7846, Validation Accuracy: 0.6823, Loss: 0.4686\n",
      "Epoch   3 Batch 1490/2109 - Train Accuracy: 0.7997, Validation Accuracy: 0.6979, Loss: 0.3283\n",
      "Epoch   3 Batch 1500/2109 - Train Accuracy: 0.8063, Validation Accuracy: 0.7170, Loss: 0.2861\n",
      "Epoch   3 Batch 1510/2109 - Train Accuracy: 0.7799, Validation Accuracy: 0.7118, Loss: 0.3374\n",
      "Epoch   3 Batch 1520/2109 - Train Accuracy: 0.7721, Validation Accuracy: 0.7274, Loss: 0.4522\n",
      "Epoch   3 Batch 1530/2109 - Train Accuracy: 0.8328, Validation Accuracy: 0.7344, Loss: 0.3875\n",
      "Epoch   3 Batch 1540/2109 - Train Accuracy: 0.8785, Validation Accuracy: 0.7448, Loss: 0.3065\n",
      "Epoch   3 Batch 1550/2109 - Train Accuracy: 0.7229, Validation Accuracy: 0.7326, Loss: 0.4657\n",
      "Epoch   3 Batch 1560/2109 - Train Accuracy: 0.7332, Validation Accuracy: 0.7240, Loss: 0.4232\n",
      "Epoch   3 Batch 1570/2109 - Train Accuracy: 0.8173, Validation Accuracy: 0.7135, Loss: 0.3333\n",
      "Epoch   3 Batch 1580/2109 - Train Accuracy: 0.7861, Validation Accuracy: 0.7222, Loss: 0.4136\n",
      "Epoch   3 Batch 1590/2109 - Train Accuracy: 0.8348, Validation Accuracy: 0.6997, Loss: 0.3601\n",
      "Epoch   3 Batch 1600/2109 - Train Accuracy: 0.8125, Validation Accuracy: 0.7378, Loss: 0.3550\n",
      "Epoch   3 Batch 1610/2109 - Train Accuracy: 0.7797, Validation Accuracy: 0.7552, Loss: 0.4593\n",
      "Epoch   3 Batch 1620/2109 - Train Accuracy: 0.7904, Validation Accuracy: 0.7170, Loss: 0.4679\n",
      "Epoch   3 Batch 1630/2109 - Train Accuracy: 0.8733, Validation Accuracy: 0.7448, Loss: 0.2832\n",
      "Epoch   3 Batch 1640/2109 - Train Accuracy: 0.8080, Validation Accuracy: 0.7483, Loss: 0.3622\n",
      "Epoch   3 Batch 1650/2109 - Train Accuracy: 0.8945, Validation Accuracy: 0.7188, Loss: 0.2462\n",
      "Epoch   3 Batch 1660/2109 - Train Accuracy: 0.8581, Validation Accuracy: 0.7257, Loss: 0.4053\n",
      "Epoch   3 Batch 1670/2109 - Train Accuracy: 0.8455, Validation Accuracy: 0.7257, Loss: 0.4273\n",
      "Epoch   3 Batch 1680/2109 - Train Accuracy: 0.5554, Validation Accuracy: 0.7344, Loss: 0.3690\n",
      "Epoch   3 Batch 1690/2109 - Train Accuracy: 0.8714, Validation Accuracy: 0.7031, Loss: 0.2472\n",
      "Epoch   3 Batch 1700/2109 - Train Accuracy: 0.7803, Validation Accuracy: 0.7153, Loss: 0.3998\n",
      "Epoch   3 Batch 1710/2109 - Train Accuracy: 0.7969, Validation Accuracy: 0.7153, Loss: 0.4840\n",
      "Epoch   3 Batch 1720/2109 - Train Accuracy: 0.8821, Validation Accuracy: 0.7049, Loss: 0.2783\n",
      "Epoch   3 Batch 1730/2109 - Train Accuracy: 0.8531, Validation Accuracy: 0.7031, Loss: 0.3428\n",
      "Epoch   3 Batch 1740/2109 - Train Accuracy: 0.8366, Validation Accuracy: 0.7396, Loss: 0.3580\n",
      "Epoch   3 Batch 1750/2109 - Train Accuracy: 0.9236, Validation Accuracy: 0.7188, Loss: 0.2008\n",
      "Epoch   3 Batch 1760/2109 - Train Accuracy: 0.9062, Validation Accuracy: 0.7014, Loss: 0.2516\n",
      "Epoch   3 Batch 1770/2109 - Train Accuracy: 0.8197, Validation Accuracy: 0.7309, Loss: 0.3407\n",
      "Epoch   3 Batch 1780/2109 - Train Accuracy: 0.8395, Validation Accuracy: 0.7326, Loss: 0.2325\n",
      "Epoch   3 Batch 1790/2109 - Train Accuracy: 0.8963, Validation Accuracy: 0.7257, Loss: 0.3993\n",
      "Epoch   3 Batch 1800/2109 - Train Accuracy: 0.8450, Validation Accuracy: 0.7378, Loss: 0.3017\n",
      "Epoch   3 Batch 1810/2109 - Train Accuracy: 0.9232, Validation Accuracy: 0.7344, Loss: 0.1642\n",
      "Epoch   3 Batch 1820/2109 - Train Accuracy: 0.8739, Validation Accuracy: 0.7118, Loss: 0.2709\n",
      "Epoch   3 Batch 1830/2109 - Train Accuracy: 0.6730, Validation Accuracy: 0.7101, Loss: 0.5713\n",
      "Epoch   3 Batch 1840/2109 - Train Accuracy: 0.6141, Validation Accuracy: 0.7170, Loss: 0.5468\n",
      "Epoch   3 Batch 1850/2109 - Train Accuracy: 0.9187, Validation Accuracy: 0.7153, Loss: 0.2096\n",
      "Epoch   3 Batch 1860/2109 - Train Accuracy: 0.8594, Validation Accuracy: 0.6892, Loss: 0.3679\n",
      "Epoch   3 Batch 1870/2109 - Train Accuracy: 0.8317, Validation Accuracy: 0.7153, Loss: 0.2825\n",
      "Epoch   3 Batch 1880/2109 - Train Accuracy: 0.8281, Validation Accuracy: 0.7240, Loss: 0.3185\n",
      "Epoch   3 Batch 1890/2109 - Train Accuracy: 0.8672, Validation Accuracy: 0.7274, Loss: 0.3249\n",
      "Epoch   3 Batch 1900/2109 - Train Accuracy: 0.8736, Validation Accuracy: 0.7274, Loss: 0.2193\n",
      "Epoch   3 Batch 1910/2109 - Train Accuracy: 0.8516, Validation Accuracy: 0.7431, Loss: 0.4375\n",
      "Epoch   3 Batch 1920/2109 - Train Accuracy: 0.7908, Validation Accuracy: 0.7552, Loss: 0.3994\n",
      "Epoch   3 Batch 1930/2109 - Train Accuracy: 0.9276, Validation Accuracy: 0.7344, Loss: 0.1792\n",
      "Epoch   3 Batch 1940/2109 - Train Accuracy: 0.8168, Validation Accuracy: 0.7135, Loss: 0.3502\n",
      "Epoch   3 Batch 1950/2109 - Train Accuracy: 0.6166, Validation Accuracy: 0.7170, Loss: 0.5275\n",
      "Epoch   3 Batch 1960/2109 - Train Accuracy: 0.4969, Validation Accuracy: 0.7118, Loss: 0.5606\n",
      "Epoch   3 Batch 1970/2109 - Train Accuracy: 0.7562, Validation Accuracy: 0.7153, Loss: 0.4942\n",
      "Epoch   3 Batch 1980/2109 - Train Accuracy: 0.8346, Validation Accuracy: 0.7240, Loss: 0.3876\n",
      "Epoch   3 Batch 1990/2109 - Train Accuracy: 0.8607, Validation Accuracy: 0.7274, Loss: 0.3130\n",
      "Epoch   3 Batch 2000/2109 - Train Accuracy: 0.8346, Validation Accuracy: 0.7083, Loss: 0.4262\n",
      "Epoch   3 Batch 2010/2109 - Train Accuracy: 0.8484, Validation Accuracy: 0.7118, Loss: 0.3203\n",
      "Epoch   3 Batch 2020/2109 - Train Accuracy: 0.8734, Validation Accuracy: 0.7309, Loss: 0.2963\n",
      "Epoch   3 Batch 2030/2109 - Train Accuracy: 0.8420, Validation Accuracy: 0.7170, Loss: 0.4602\n",
      "Epoch   3 Batch 2040/2109 - Train Accuracy: 0.8774, Validation Accuracy: 0.6823, Loss: 0.2781\n",
      "Epoch   3 Batch 2050/2109 - Train Accuracy: 0.5656, Validation Accuracy: 0.7049, Loss: 0.3566\n",
      "Epoch   3 Batch 2060/2109 - Train Accuracy: 0.9375, Validation Accuracy: 0.6823, Loss: 0.2147\n",
      "Epoch   3 Batch 2070/2109 - Train Accuracy: 0.7734, Validation Accuracy: 0.7118, Loss: 0.5227\n",
      "Epoch   3 Batch 2080/2109 - Train Accuracy: 0.8344, Validation Accuracy: 0.6927, Loss: 0.3245\n",
      "Epoch   3 Batch 2090/2109 - Train Accuracy: 0.7517, Validation Accuracy: 0.6476, Loss: 0.4676\n",
      "Epoch   3 Batch 2100/2109 - Train Accuracy: 0.9385, Validation Accuracy: 0.6632, Loss: 0.1779\n",
      "Epoch   4 Batch   10/2109 - Train Accuracy: 0.7716, Validation Accuracy: 0.6771, Loss: 0.4451\n",
      "Epoch   4 Batch   20/2109 - Train Accuracy: 0.7396, Validation Accuracy: 0.7083, Loss: 0.3930\n",
      "Epoch   4 Batch   30/2109 - Train Accuracy: 0.7865, Validation Accuracy: 0.7066, Loss: 0.5910\n",
      "Epoch   4 Batch   40/2109 - Train Accuracy: 0.7422, Validation Accuracy: 0.7483, Loss: 0.4380\n",
      "Epoch   4 Batch   50/2109 - Train Accuracy: 0.8042, Validation Accuracy: 0.7431, Loss: 0.3855\n",
      "Epoch   4 Batch   60/2109 - Train Accuracy: 0.7656, Validation Accuracy: 0.7274, Loss: 0.3956\n",
      "Epoch   4 Batch   70/2109 - Train Accuracy: 0.6982, Validation Accuracy: 0.7257, Loss: 0.5443\n",
      "Epoch   4 Batch   80/2109 - Train Accuracy: 0.7250, Validation Accuracy: 0.7396, Loss: 0.5826\n",
      "Epoch   4 Batch   90/2109 - Train Accuracy: 0.6062, Validation Accuracy: 0.7274, Loss: 0.6259\n",
      "Epoch   4 Batch  100/2109 - Train Accuracy: 0.8137, Validation Accuracy: 0.7378, Loss: 0.4444\n",
      "Epoch   4 Batch  110/2109 - Train Accuracy: 0.5920, Validation Accuracy: 0.7431, Loss: 0.6166\n",
      "Epoch   4 Batch  120/2109 - Train Accuracy: 0.9036, Validation Accuracy: 0.7535, Loss: 0.2709\n",
      "Epoch   4 Batch  130/2109 - Train Accuracy: 0.8810, Validation Accuracy: 0.7274, Loss: 0.2711\n",
      "Epoch   4 Batch  140/2109 - Train Accuracy: 0.7017, Validation Accuracy: 0.7361, Loss: 0.5254\n",
      "Epoch   4 Batch  150/2109 - Train Accuracy: 0.7227, Validation Accuracy: 0.7413, Loss: 0.6100\n",
      "Epoch   4 Batch  160/2109 - Train Accuracy: 0.8344, Validation Accuracy: 0.7170, Loss: 0.3487\n",
      "Epoch   4 Batch  170/2109 - Train Accuracy: 0.9261, Validation Accuracy: 0.7326, Loss: 0.2158\n",
      "Epoch   4 Batch  180/2109 - Train Accuracy: 0.8951, Validation Accuracy: 0.7448, Loss: 0.1865\n",
      "Epoch   4 Batch  190/2109 - Train Accuracy: 0.8702, Validation Accuracy: 0.7413, Loss: 0.2451\n",
      "Epoch   4 Batch  200/2109 - Train Accuracy: 0.8594, Validation Accuracy: 0.7326, Loss: 0.3432\n",
      "Epoch   4 Batch  210/2109 - Train Accuracy: 0.7750, Validation Accuracy: 0.7396, Loss: 0.6267\n",
      "Epoch   4 Batch  220/2109 - Train Accuracy: 0.8403, Validation Accuracy: 0.7569, Loss: 0.4107\n",
      "Epoch   4 Batch  230/2109 - Train Accuracy: 0.8464, Validation Accuracy: 0.7378, Loss: 0.3372\n",
      "Epoch   4 Batch  240/2109 - Train Accuracy: 0.9432, Validation Accuracy: 0.7517, Loss: 0.2542\n",
      "Epoch   4 Batch  250/2109 - Train Accuracy: 0.8253, Validation Accuracy: 0.7361, Loss: 0.4030\n",
      "Epoch   4 Batch  260/2109 - Train Accuracy: 0.9187, Validation Accuracy: 0.7500, Loss: 0.1683\n",
      "Epoch   4 Batch  270/2109 - Train Accuracy: 0.8008, Validation Accuracy: 0.7465, Loss: 0.3817\n",
      "Epoch   4 Batch  280/2109 - Train Accuracy: 0.8398, Validation Accuracy: 0.7639, Loss: 0.3080\n",
      "Epoch   4 Batch  290/2109 - Train Accuracy: 0.8875, Validation Accuracy: 0.7639, Loss: 0.2888\n",
      "Epoch   4 Batch  300/2109 - Train Accuracy: 0.7946, Validation Accuracy: 0.7622, Loss: 0.4172\n",
      "Epoch   4 Batch  310/2109 - Train Accuracy: 0.7428, Validation Accuracy: 0.7448, Loss: 0.4932\n",
      "Epoch   4 Batch  320/2109 - Train Accuracy: 0.8352, Validation Accuracy: 0.7257, Loss: 0.3856\n",
      "Epoch   4 Batch  330/2109 - Train Accuracy: 0.7908, Validation Accuracy: 0.7240, Loss: 0.4588\n",
      "Epoch   4 Batch  340/2109 - Train Accuracy: 0.8774, Validation Accuracy: 0.7500, Loss: 0.3051\n",
      "Epoch   4 Batch  350/2109 - Train Accuracy: 0.8000, Validation Accuracy: 0.7691, Loss: 0.4117\n",
      "Epoch   4 Batch  360/2109 - Train Accuracy: 0.8058, Validation Accuracy: 0.7656, Loss: 0.3683\n",
      "Epoch   4 Batch  370/2109 - Train Accuracy: 0.7730, Validation Accuracy: 0.7500, Loss: 0.3189\n",
      "Epoch   4 Batch  380/2109 - Train Accuracy: 0.7375, Validation Accuracy: 0.7517, Loss: 0.4352\n",
      "Epoch   4 Batch  390/2109 - Train Accuracy: 0.8652, Validation Accuracy: 0.7639, Loss: 0.2411\n",
      "Epoch   4 Batch  400/2109 - Train Accuracy: 0.7701, Validation Accuracy: 0.7587, Loss: 0.3256\n",
      "Epoch   4 Batch  410/2109 - Train Accuracy: 0.8264, Validation Accuracy: 0.7622, Loss: 0.3596\n",
      "Epoch   4 Batch  420/2109 - Train Accuracy: 0.8021, Validation Accuracy: 0.7760, Loss: 0.4527\n",
      "Epoch   4 Batch  430/2109 - Train Accuracy: 0.6263, Validation Accuracy: 0.7830, Loss: 0.4639\n",
      "Epoch   4 Batch  440/2109 - Train Accuracy: 0.8168, Validation Accuracy: 0.7812, Loss: 0.3507\n",
      "Epoch   4 Batch  450/2109 - Train Accuracy: 0.8778, Validation Accuracy: 0.7674, Loss: 0.2842\n",
      "Epoch   4 Batch  460/2109 - Train Accuracy: 0.8717, Validation Accuracy: 0.7726, Loss: 0.2106\n",
      "Epoch   4 Batch  470/2109 - Train Accuracy: 0.7727, Validation Accuracy: 0.7812, Loss: 0.4469\n",
      "Epoch   4 Batch  480/2109 - Train Accuracy: 0.8017, Validation Accuracy: 0.7986, Loss: 0.3872\n",
      "Epoch   4 Batch  490/2109 - Train Accuracy: 0.7906, Validation Accuracy: 0.7882, Loss: 0.3445\n",
      "Epoch   4 Batch  500/2109 - Train Accuracy: 0.7695, Validation Accuracy: 0.7934, Loss: 0.4884\n",
      "Epoch   4 Batch  510/2109 - Train Accuracy: 0.7445, Validation Accuracy: 0.7951, Loss: 0.4107\n",
      "Epoch   4 Batch  520/2109 - Train Accuracy: 0.8594, Validation Accuracy: 0.7760, Loss: 0.3006\n",
      "Epoch   4 Batch  530/2109 - Train Accuracy: 0.8906, Validation Accuracy: 0.7882, Loss: 0.3094\n",
      "Epoch   4 Batch  540/2109 - Train Accuracy: 0.8835, Validation Accuracy: 0.7865, Loss: 0.2659\n",
      "Epoch   4 Batch  550/2109 - Train Accuracy: 0.7891, Validation Accuracy: 0.7743, Loss: 0.3852\n",
      "Epoch   4 Batch  560/2109 - Train Accuracy: 0.6562, Validation Accuracy: 0.7899, Loss: 0.5888\n",
      "Epoch   4 Batch  570/2109 - Train Accuracy: 0.8760, Validation Accuracy: 0.7622, Loss: 0.2225\n",
      "Epoch   4 Batch  580/2109 - Train Accuracy: 0.8971, Validation Accuracy: 0.7552, Loss: 0.2771\n",
      "Epoch   4 Batch  590/2109 - Train Accuracy: 0.7224, Validation Accuracy: 0.7656, Loss: 0.4696\n",
      "Epoch   4 Batch  600/2109 - Train Accuracy: 0.7400, Validation Accuracy: 0.7639, Loss: 0.5168\n",
      "Epoch   4 Batch  610/2109 - Train Accuracy: 0.8307, Validation Accuracy: 0.7569, Loss: 0.3287\n",
      "Epoch   4 Batch  620/2109 - Train Accuracy: 0.8034, Validation Accuracy: 0.7604, Loss: 0.4463\n",
      "Epoch   4 Batch  630/2109 - Train Accuracy: 0.8229, Validation Accuracy: 0.7344, Loss: 0.2881\n",
      "Epoch   4 Batch  640/2109 - Train Accuracy: 0.8073, Validation Accuracy: 0.7396, Loss: 0.3527\n",
      "Epoch   4 Batch  650/2109 - Train Accuracy: 0.9031, Validation Accuracy: 0.7535, Loss: 0.2489\n",
      "Epoch   4 Batch  660/2109 - Train Accuracy: 0.8078, Validation Accuracy: 0.7535, Loss: 0.3026\n",
      "Epoch   4 Batch  670/2109 - Train Accuracy: 0.8203, Validation Accuracy: 0.7500, Loss: 0.3478\n",
      "Epoch   4 Batch  680/2109 - Train Accuracy: 0.7548, Validation Accuracy: 0.7153, Loss: 0.3629\n",
      "Epoch   4 Batch  690/2109 - Train Accuracy: 0.8305, Validation Accuracy: 0.7622, Loss: 0.2390\n",
      "Epoch   4 Batch  700/2109 - Train Accuracy: 0.9176, Validation Accuracy: 0.7205, Loss: 0.2401\n",
      "Epoch   4 Batch  710/2109 - Train Accuracy: 0.6065, Validation Accuracy: 0.7396, Loss: 0.5514\n",
      "Epoch   4 Batch  720/2109 - Train Accuracy: 0.8938, Validation Accuracy: 0.7448, Loss: 0.3071\n",
      "Epoch   4 Batch  730/2109 - Train Accuracy: 0.7930, Validation Accuracy: 0.7344, Loss: 0.5051\n",
      "Epoch   4 Batch  740/2109 - Train Accuracy: 0.6289, Validation Accuracy: 0.7396, Loss: 0.6079\n",
      "Epoch   4 Batch  750/2109 - Train Accuracy: 0.8750, Validation Accuracy: 0.7483, Loss: 0.2777\n",
      "Epoch   4 Batch  760/2109 - Train Accuracy: 0.7756, Validation Accuracy: 0.7326, Loss: 0.5355\n",
      "Epoch   4 Batch  770/2109 - Train Accuracy: 0.8906, Validation Accuracy: 0.7500, Loss: 0.2023\n",
      "Epoch   4 Batch  780/2109 - Train Accuracy: 0.8798, Validation Accuracy: 0.7552, Loss: 0.2079\n",
      "Epoch   4 Batch  790/2109 - Train Accuracy: 0.9328, Validation Accuracy: 0.7552, Loss: 0.2297\n",
      "Epoch   4 Batch  800/2109 - Train Accuracy: 0.9134, Validation Accuracy: 0.7569, Loss: 0.2223\n",
      "Epoch   4 Batch  810/2109 - Train Accuracy: 0.7984, Validation Accuracy: 0.7569, Loss: 0.4066\n",
      "Epoch   4 Batch  820/2109 - Train Accuracy: 0.9261, Validation Accuracy: 0.7396, Loss: 0.1568\n",
      "Epoch   4 Batch  830/2109 - Train Accuracy: 0.8641, Validation Accuracy: 0.7465, Loss: 0.2821\n",
      "Epoch   4 Batch  840/2109 - Train Accuracy: 0.8778, Validation Accuracy: 0.7500, Loss: 0.2527\n",
      "Epoch   4 Batch  850/2109 - Train Accuracy: 0.8844, Validation Accuracy: 0.7413, Loss: 0.3543\n",
      "Epoch   4 Batch  860/2109 - Train Accuracy: 0.7433, Validation Accuracy: 0.7569, Loss: 0.4723\n",
      "Epoch   4 Batch  870/2109 - Train Accuracy: 0.8859, Validation Accuracy: 0.7483, Loss: 0.2926\n",
      "Epoch   4 Batch  880/2109 - Train Accuracy: 0.6435, Validation Accuracy: 0.7378, Loss: 0.7787\n",
      "Epoch   4 Batch  890/2109 - Train Accuracy: 0.7891, Validation Accuracy: 0.7361, Loss: 0.3848\n",
      "Epoch   4 Batch  900/2109 - Train Accuracy: 0.8542, Validation Accuracy: 0.7604, Loss: 0.2621\n",
      "Epoch   4 Batch  910/2109 - Train Accuracy: 0.7386, Validation Accuracy: 0.7396, Loss: 0.5184\n",
      "Epoch   4 Batch  920/2109 - Train Accuracy: 0.7065, Validation Accuracy: 0.7222, Loss: 0.4676\n",
      "Epoch   4 Batch  930/2109 - Train Accuracy: 0.7688, Validation Accuracy: 0.7153, Loss: 0.3934\n",
      "Epoch   4 Batch  940/2109 - Train Accuracy: 0.7393, Validation Accuracy: 0.7292, Loss: 0.3509\n",
      "Epoch   4 Batch  950/2109 - Train Accuracy: 0.8031, Validation Accuracy: 0.7205, Loss: 0.3237\n",
      "Epoch   4 Batch  960/2109 - Train Accuracy: 0.7723, Validation Accuracy: 0.7326, Loss: 0.5049\n",
      "Epoch   4 Batch  970/2109 - Train Accuracy: 0.9375, Validation Accuracy: 0.7431, Loss: 0.1805\n",
      "Epoch   4 Batch  980/2109 - Train Accuracy: 0.7467, Validation Accuracy: 0.7413, Loss: 0.3475\n",
      "Epoch   4 Batch  990/2109 - Train Accuracy: 0.8494, Validation Accuracy: 0.7500, Loss: 0.4049\n",
      "Epoch   4 Batch 1000/2109 - Train Accuracy: 0.9219, Validation Accuracy: 0.7483, Loss: 0.2105\n",
      "Epoch   4 Batch 1010/2109 - Train Accuracy: 0.8210, Validation Accuracy: 0.7674, Loss: 0.3737\n",
      "Epoch   4 Batch 1020/2109 - Train Accuracy: 0.8507, Validation Accuracy: 0.7535, Loss: 0.2855\n",
      "Epoch   4 Batch 1030/2109 - Train Accuracy: 0.8537, Validation Accuracy: 0.7309, Loss: 0.3086\n",
      "Epoch   4 Batch 1040/2109 - Train Accuracy: 0.9048, Validation Accuracy: 0.7483, Loss: 0.2574\n",
      "Epoch   4 Batch 1050/2109 - Train Accuracy: 0.7940, Validation Accuracy: 0.7170, Loss: 0.3084\n",
      "Epoch   4 Batch 1060/2109 - Train Accuracy: 0.8707, Validation Accuracy: 0.7396, Loss: 0.2631\n",
      "Epoch   4 Batch 1070/2109 - Train Accuracy: 0.9016, Validation Accuracy: 0.7326, Loss: 0.2820\n",
      "Epoch   4 Batch 1080/2109 - Train Accuracy: 0.8628, Validation Accuracy: 0.7448, Loss: 0.3209\n",
      "Epoch   4 Batch 1090/2109 - Train Accuracy: 0.6922, Validation Accuracy: 0.7413, Loss: 0.5497\n",
      "Epoch   4 Batch 1100/2109 - Train Accuracy: 0.7878, Validation Accuracy: 0.7413, Loss: 0.4052\n",
      "Epoch   4 Batch 1110/2109 - Train Accuracy: 0.8529, Validation Accuracy: 0.7431, Loss: 0.2639\n",
      "Epoch   4 Batch 1120/2109 - Train Accuracy: 0.7704, Validation Accuracy: 0.7743, Loss: 0.4162\n",
      "Epoch   4 Batch 1130/2109 - Train Accuracy: 0.8776, Validation Accuracy: 0.7795, Loss: 0.2765\n",
      "Epoch   4 Batch 1140/2109 - Train Accuracy: 0.7083, Validation Accuracy: 0.7535, Loss: 0.5441\n",
      "Epoch   4 Batch 1150/2109 - Train Accuracy: 0.8112, Validation Accuracy: 0.7448, Loss: 0.3996\n",
      "Epoch   4 Batch 1160/2109 - Train Accuracy: 0.9000, Validation Accuracy: 0.7500, Loss: 0.2062\n",
      "Epoch   4 Batch 1170/2109 - Train Accuracy: 0.8172, Validation Accuracy: 0.7500, Loss: 0.3112\n",
      "Epoch   4 Batch 1180/2109 - Train Accuracy: 0.8661, Validation Accuracy: 0.7795, Loss: 0.2942\n",
      "Epoch   4 Batch 1190/2109 - Train Accuracy: 0.9062, Validation Accuracy: 0.7847, Loss: 0.2396\n",
      "Epoch   4 Batch 1200/2109 - Train Accuracy: 0.8125, Validation Accuracy: 0.6875, Loss: 0.2695\n",
      "Epoch   4 Batch 1210/2109 - Train Accuracy: 0.8828, Validation Accuracy: 0.7483, Loss: 0.2902\n",
      "Epoch   4 Batch 1220/2109 - Train Accuracy: 0.8270, Validation Accuracy: 0.7535, Loss: 0.3418\n",
      "Epoch   4 Batch 1230/2109 - Train Accuracy: 0.8242, Validation Accuracy: 0.7569, Loss: 0.4290\n",
      "Epoch   4 Batch 1240/2109 - Train Accuracy: 0.9190, Validation Accuracy: 0.7535, Loss: 0.2399\n",
      "Epoch   4 Batch 1250/2109 - Train Accuracy: 0.6500, Validation Accuracy: 0.7674, Loss: 0.6077\n",
      "Epoch   4 Batch 1260/2109 - Train Accuracy: 0.7902, Validation Accuracy: 0.7535, Loss: 0.4266\n",
      "Epoch   4 Batch 1270/2109 - Train Accuracy: 0.8125, Validation Accuracy: 0.7240, Loss: 0.3523\n",
      "Epoch   4 Batch 1280/2109 - Train Accuracy: 0.8281, Validation Accuracy: 0.7431, Loss: 0.4038\n",
      "Epoch   4 Batch 1290/2109 - Train Accuracy: 0.8234, Validation Accuracy: 0.7587, Loss: 0.4233\n",
      "Epoch   4 Batch 1300/2109 - Train Accuracy: 0.8821, Validation Accuracy: 0.7500, Loss: 0.2175\n",
      "Epoch   4 Batch 1310/2109 - Train Accuracy: 0.8060, Validation Accuracy: 0.7448, Loss: 0.4178\n",
      "Epoch   4 Batch 1320/2109 - Train Accuracy: 0.8082, Validation Accuracy: 0.7535, Loss: 0.3747\n",
      "Epoch   4 Batch 1330/2109 - Train Accuracy: 0.8320, Validation Accuracy: 0.7674, Loss: 0.3598\n",
      "Epoch   4 Batch 1340/2109 - Train Accuracy: 0.7500, Validation Accuracy: 0.7448, Loss: 0.4924\n",
      "Epoch   4 Batch 1350/2109 - Train Accuracy: 0.7750, Validation Accuracy: 0.7517, Loss: 0.5086\n",
      "Epoch   4 Batch 1360/2109 - Train Accuracy: 0.7634, Validation Accuracy: 0.7639, Loss: 0.4719\n",
      "Epoch   4 Batch 1370/2109 - Train Accuracy: 0.8504, Validation Accuracy: 0.7396, Loss: 0.3913\n",
      "Epoch   4 Batch 1380/2109 - Train Accuracy: 0.8605, Validation Accuracy: 0.7465, Loss: 0.3015\n",
      "Epoch   4 Batch 1390/2109 - Train Accuracy: 0.8047, Validation Accuracy: 0.7240, Loss: 0.3272\n",
      "Epoch   4 Batch 1400/2109 - Train Accuracy: 0.8602, Validation Accuracy: 0.7326, Loss: 0.2211\n",
      "Epoch   4 Batch 1410/2109 - Train Accuracy: 0.8281, Validation Accuracy: 0.7240, Loss: 0.3652\n",
      "Epoch   4 Batch 1420/2109 - Train Accuracy: 0.8411, Validation Accuracy: 0.7569, Loss: 0.2765\n",
      "Epoch   4 Batch 1430/2109 - Train Accuracy: 0.8864, Validation Accuracy: 0.7569, Loss: 0.2530\n",
      "Epoch   4 Batch 1440/2109 - Train Accuracy: 0.8016, Validation Accuracy: 0.7326, Loss: 0.3631\n",
      "Epoch   4 Batch 1450/2109 - Train Accuracy: 0.8646, Validation Accuracy: 0.7361, Loss: 0.2925\n",
      "Epoch   4 Batch 1460/2109 - Train Accuracy: 0.8054, Validation Accuracy: 0.7569, Loss: 0.3440\n",
      "Epoch   4 Batch 1470/2109 - Train Accuracy: 0.8151, Validation Accuracy: 0.7483, Loss: 0.2807\n",
      "Epoch   4 Batch 1480/2109 - Train Accuracy: 0.8460, Validation Accuracy: 0.7396, Loss: 0.3445\n",
      "Epoch   4 Batch 1490/2109 - Train Accuracy: 0.8366, Validation Accuracy: 0.7483, Loss: 0.2648\n",
      "Epoch   4 Batch 1500/2109 - Train Accuracy: 0.8438, Validation Accuracy: 0.7569, Loss: 0.2296\n",
      "Epoch   4 Batch 1510/2109 - Train Accuracy: 0.8685, Validation Accuracy: 0.7344, Loss: 0.2330\n",
      "Epoch   4 Batch 1520/2109 - Train Accuracy: 0.8190, Validation Accuracy: 0.7378, Loss: 0.3461\n",
      "Epoch   4 Batch 1530/2109 - Train Accuracy: 0.8797, Validation Accuracy: 0.7500, Loss: 0.3264\n",
      "Epoch   4 Batch 1540/2109 - Train Accuracy: 0.8958, Validation Accuracy: 0.7674, Loss: 0.2442\n",
      "Epoch   4 Batch 1550/2109 - Train Accuracy: 0.7948, Validation Accuracy: 0.7292, Loss: 0.3272\n",
      "Epoch   4 Batch 1560/2109 - Train Accuracy: 0.7933, Validation Accuracy: 0.7361, Loss: 0.3598\n",
      "Epoch   4 Batch 1570/2109 - Train Accuracy: 0.8606, Validation Accuracy: 0.7448, Loss: 0.2735\n",
      "Epoch   4 Batch 1580/2109 - Train Accuracy: 0.7933, Validation Accuracy: 0.7413, Loss: 0.3699\n",
      "Epoch   4 Batch 1590/2109 - Train Accuracy: 0.8270, Validation Accuracy: 0.7309, Loss: 0.3235\n",
      "Epoch   4 Batch 1600/2109 - Train Accuracy: 0.8203, Validation Accuracy: 0.7448, Loss: 0.2865\n",
      "Epoch   4 Batch 1610/2109 - Train Accuracy: 0.8078, Validation Accuracy: 0.7535, Loss: 0.3748\n",
      "Epoch   4 Batch 1620/2109 - Train Accuracy: 0.8320, Validation Accuracy: 0.7483, Loss: 0.4029\n",
      "Epoch   4 Batch 1630/2109 - Train Accuracy: 0.8785, Validation Accuracy: 0.7674, Loss: 0.2197\n",
      "Epoch   4 Batch 1640/2109 - Train Accuracy: 0.8471, Validation Accuracy: 0.7517, Loss: 0.2985\n",
      "Epoch   4 Batch 1650/2109 - Train Accuracy: 0.9362, Validation Accuracy: 0.7361, Loss: 0.2089\n",
      "Epoch   4 Batch 1660/2109 - Train Accuracy: 0.8750, Validation Accuracy: 0.7274, Loss: 0.3511\n",
      "Epoch   4 Batch 1670/2109 - Train Accuracy: 0.9080, Validation Accuracy: 0.7465, Loss: 0.2750\n",
      "Epoch   4 Batch 1680/2109 - Train Accuracy: 0.9290, Validation Accuracy: 0.7465, Loss: 0.2016\n",
      "Epoch   4 Batch 1690/2109 - Train Accuracy: 0.8846, Validation Accuracy: 0.7569, Loss: 0.1842\n",
      "Epoch   4 Batch 1700/2109 - Train Accuracy: 0.7939, Validation Accuracy: 0.7483, Loss: 0.3408\n",
      "Epoch   4 Batch 1710/2109 - Train Accuracy: 0.8875, Validation Accuracy: 0.7500, Loss: 0.3112\n",
      "Epoch   4 Batch 1720/2109 - Train Accuracy: 0.8892, Validation Accuracy: 0.7483, Loss: 0.2282\n",
      "Epoch   4 Batch 1730/2109 - Train Accuracy: 0.8547, Validation Accuracy: 0.7205, Loss: 0.2955\n",
      "Epoch   4 Batch 1740/2109 - Train Accuracy: 0.8281, Validation Accuracy: 0.7448, Loss: 0.3025\n",
      "Epoch   4 Batch 1750/2109 - Train Accuracy: 0.9653, Validation Accuracy: 0.7500, Loss: 0.1137\n",
      "Epoch   4 Batch 1760/2109 - Train Accuracy: 0.9313, Validation Accuracy: 0.7465, Loss: 0.1930\n",
      "Epoch   4 Batch 1770/2109 - Train Accuracy: 0.8425, Validation Accuracy: 0.7448, Loss: 0.2804\n",
      "Epoch   4 Batch 1780/2109 - Train Accuracy: 0.8821, Validation Accuracy: 0.7448, Loss: 0.1646\n",
      "Epoch   4 Batch 1790/2109 - Train Accuracy: 0.9162, Validation Accuracy: 0.7535, Loss: 0.2961\n",
      "Epoch   4 Batch 1800/2109 - Train Accuracy: 0.9002, Validation Accuracy: 0.7413, Loss: 0.2379\n",
      "Epoch   4 Batch 1810/2109 - Train Accuracy: 0.9284, Validation Accuracy: 0.7465, Loss: 0.1308\n",
      "Epoch   4 Batch 1820/2109 - Train Accuracy: 0.9040, Validation Accuracy: 0.7465, Loss: 0.2302\n",
      "Epoch   4 Batch 1830/2109 - Train Accuracy: 0.7355, Validation Accuracy: 0.7222, Loss: 0.4780\n",
      "Epoch   4 Batch 1840/2109 - Train Accuracy: 0.6633, Validation Accuracy: 0.7326, Loss: 0.4713\n",
      "Epoch   4 Batch 1850/2109 - Train Accuracy: 0.9297, Validation Accuracy: 0.7396, Loss: 0.1300\n",
      "Epoch   4 Batch 1860/2109 - Train Accuracy: 0.9036, Validation Accuracy: 0.7500, Loss: 0.2926\n",
      "Epoch   4 Batch 1870/2109 - Train Accuracy: 0.8774, Validation Accuracy: 0.7413, Loss: 0.2342\n",
      "Epoch   4 Batch 1880/2109 - Train Accuracy: 0.8494, Validation Accuracy: 0.7413, Loss: 0.2630\n",
      "Epoch   4 Batch 1890/2109 - Train Accuracy: 0.8641, Validation Accuracy: 0.7552, Loss: 0.2370\n",
      "Epoch   4 Batch 1900/2109 - Train Accuracy: 0.8963, Validation Accuracy: 0.7517, Loss: 0.1601\n",
      "Epoch   4 Batch 1910/2109 - Train Accuracy: 0.8516, Validation Accuracy: 0.7431, Loss: 0.3380\n",
      "Epoch   4 Batch 1920/2109 - Train Accuracy: 0.8255, Validation Accuracy: 0.7396, Loss: 0.3417\n",
      "Epoch   4 Batch 1930/2109 - Train Accuracy: 0.9276, Validation Accuracy: 0.7552, Loss: 0.1580\n",
      "Epoch   4 Batch 1940/2109 - Train Accuracy: 0.8395, Validation Accuracy: 0.7656, Loss: 0.3155\n",
      "Epoch   4 Batch 1950/2109 - Train Accuracy: 0.6839, Validation Accuracy: 0.7378, Loss: 0.4054\n",
      "Epoch   4 Batch 1960/2109 - Train Accuracy: 0.6427, Validation Accuracy: 0.7344, Loss: 0.4085\n",
      "Epoch   4 Batch 1970/2109 - Train Accuracy: 0.8219, Validation Accuracy: 0.7361, Loss: 0.3817\n",
      "Epoch   4 Batch 1980/2109 - Train Accuracy: 0.8581, Validation Accuracy: 0.7622, Loss: 0.3231\n",
      "Epoch   4 Batch 1990/2109 - Train Accuracy: 0.8594, Validation Accuracy: 0.7378, Loss: 0.2661\n",
      "Epoch   4 Batch 2000/2109 - Train Accuracy: 0.8372, Validation Accuracy: 0.7188, Loss: 0.3774\n",
      "Epoch   4 Batch 2010/2109 - Train Accuracy: 0.8797, Validation Accuracy: 0.7448, Loss: 0.2372\n",
      "Epoch   4 Batch 2020/2109 - Train Accuracy: 0.8875, Validation Accuracy: 0.7257, Loss: 0.2371\n",
      "Epoch   4 Batch 2030/2109 - Train Accuracy: 0.8698, Validation Accuracy: 0.7135, Loss: 0.3078\n",
      "Epoch   4 Batch 2040/2109 - Train Accuracy: 0.9087, Validation Accuracy: 0.7292, Loss: 0.2176\n",
      "Epoch   4 Batch 2050/2109 - Train Accuracy: 0.5828, Validation Accuracy: 0.7257, Loss: 0.2471\n",
      "Epoch   4 Batch 2060/2109 - Train Accuracy: 0.9453, Validation Accuracy: 0.7483, Loss: 0.1714\n",
      "Epoch   4 Batch 2070/2109 - Train Accuracy: 0.8138, Validation Accuracy: 0.7188, Loss: 0.4304\n",
      "Epoch   4 Batch 2080/2109 - Train Accuracy: 0.9016, Validation Accuracy: 0.6997, Loss: 0.2688\n",
      "Epoch   4 Batch 2090/2109 - Train Accuracy: 0.7934, Validation Accuracy: 0.6944, Loss: 0.4209\n",
      "Epoch   4 Batch 2100/2109 - Train Accuracy: 0.9424, Validation Accuracy: 0.7049, Loss: 0.1484\n",
      "Model Trained and Saved\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))\n",
    "\n",
    "# Split data to training and validation sets\n",
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "valid_source = source_int_text[:batch_size]\n",
    "valid_target = target_int_text[:batch_size]\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths ) = next(get_batches(valid_source,valid_target,batch_size,source_vocab_to_int['<PAD>'],target_vocab_to_int['<PAD>']))\n",
    "\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "                get_batches(train_source, train_target, batch_size,\n",
    "                            source_vocab_to_int['<PAD>'],\n",
    "                            target_vocab_to_int['<PAD>'])):\n",
    "\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 source_sequence_length: sources_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "\n",
    "\n",
    "                batch_train_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: source_batch,\n",
    "                     source_sequence_length: sources_lengths,\n",
    "                     target_sequence_length: targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "\n",
    "                batch_valid_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: valid_sources_batch,\n",
    "                     source_sequence_length: valid_sources_lengths,\n",
    "                     target_sequence_length: valid_targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "\n",
    "                valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)\n",
    "\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n",
    "                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "pickle.dump(save_path, open('params.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with open('preprocess.p', mode='rb') as in_file:\n",
    "    LOADED = pickle.load(in_file)\n",
    "_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = LOADED\n",
    "load_path = pickle.load(open('params.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#XXXX MODIFIED FOR OUR PROBLEM XXXX\n",
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert a word to a sequence of ids\n",
    "    :param sentence: String\n",
    "    :param vocab_to_int: Dictionary to go from the words to an id\n",
    "    :return: List of word ids\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    '''Prepare the text for the model'''\n",
    "    seq=[]\n",
    "    for char in sentence:\n",
    "        if char not in vocab_to_int:\n",
    "            seq.append(vocab_to_int['UNK'])\n",
    "        else:\n",
    "            seq.append(vocab_to_int[char])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dev\n",
      "Input\n",
      "  Word Ids:      [27, 4, 9, 8, 5, 10, 3, 8, 8]\n",
      "  English Word: ['q', 'u', 'e', 's', 't', 'r', 'o', 's', 's']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [53, 81, 31, 68, 70, 67, 10, 68, 85]\n",
      "  Phones: K W EH1 S T R AH0 S <EOS>\n"
     ]
    }
   ],
   "source": [
    "translate_sentence = 'questross'\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    source_sequence_length = loaded_graph.get_tensor_by_name('source_sequence_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,\n",
    "                                         target_sequence_length: [len(translate_sentence)*2]*batch_size,\n",
    "                                         source_sequence_length: [len(translate_sentence)]*batch_size,\n",
    "                                         keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Word: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_logits]))\n",
    "print('  Phones: {}'.format(\" \".join([target_int_to_vocab[i] for i in translate_logits])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
